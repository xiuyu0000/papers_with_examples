{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb0a189",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SSD系列算法理论介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06c16fb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SSD网络框架整体介绍\n",
    "\n",
    "[原论文地址](https://arxiv.org/abs/1512.02325)\n",
    "\n",
    "SSD(Single Shot MultiBox Detector)是作者Wei Liu 于2016年在ECCV上发表的论文。当输入是300×300的网络在VOC2007测试集上达到74.3%的mAP，检测速度达到59FPS，对于输入是512×512的网络达到了76.9%的mAP，超越了当时的Faster-RCNN(73.2%)。由于Faster-RCNN只使用了最后的conv5_3的特征图作为特征预测层，导致其对小目标物体的检测效果不佳，而SSD目标检测网络则使用了多个特征图作为特征预测层。网络具体结构如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914a334d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"./images/SSD整体框架结构图.png\" width=\"85%\" height=\"65%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe4c01",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"./images/VGG_16.png\" width=\"80%\" height=\"60%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaabb29c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "网络沿用了[VGG-16](https://arxiv.org/pdf/1409.1556.pdf)的Conv5_3层之前的所有结构，将VGG-16的第5个池化层(pool_5)从2×2，步长2改为3×3，步长1，因此通过修改后的pool_5特征图的大小不变，依旧是Conv5_3的输出大小19×19×512，将VGG-16的两个全连接层(FC6 & FC7)改为两个卷积层(Conv6 & Conv7)，随后增加了4个卷积层。\n",
    "\n",
    "随着网络层数的加深，提取到的特征信息抽象程度也随之加大，高层语义信息中小目标物体的特征信息会减少，因此，网络提取最后选取Conv4_3、Conv7、Conv8_2、Conv9_2、Conv10_2、Conv11_2的特征图作为预测特征层，从而实现针对不同大小物体的目标检测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f524d432",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"./images/不同大小的特征图检测不同大小的物体.png\" width=\"50%\" height=\"50%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eef9008",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 预测器的实现\n",
    "\n",
    "3×3卷积核实现类别分数预测以及坐标偏移量回归。对于每个预测特征层上的每个位置，会有k个默认框，对每个默认框进行预测，所以输出大小为：\n",
    "\n",
    "$$m×n×k×(c+4)$$\n",
    "\n",
    "其中，$m,n$为当前特征预测层的宽高，$k$为预测特征层每个位置上产生的默认框的个数，$c$为加上背景后的类别数，$4$为边界框坐标$(x,y,w,h)$回归参数的个数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a98f2e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "NOTCIE: **默认生成框**、**正负样本匹配**以及**损失函数**将在后续部分结合代码介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f0ddb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c91561",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ 本次实验选用的数据集为VOC2012，一共有17125张图片及其标注信息\n",
    "+ 其中将 **70%** 的数据用于**训练**任务，其余 **30%** 用于**验证**任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb9ab9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 数据集下载\n",
    "\n",
    "+ 数据下载，并解压到   **'./dataset'**   路径中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe2bf71",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start download,[File size]:1840.75 MB\n",
      "[下载进度]:>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>100.00%                                                                                                                                                                                                                      \n",
      "Download completed!,times: 746.80秒\n",
      "Successfully unzip download flower dataset from website!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "# 自动下载并解压数据集到指定文件夹内\n",
    "def download_and_unzip(url, path):\n",
    "    if not os.path.exists(path):   # 看是否有该文件夹，没有则创建文件夹\n",
    "        os.mkdir(path)\n",
    "    file_path = os.path.join(path, 'VOC.zip')\n",
    "    start = time.time() #下载开始时间\n",
    "    user, password = 'tyx_neu', 'Sportlab307'\n",
    "    resp = requests.get(url, auth=(user, password), stream=True)      #把下载地址发送给requests模块\n",
    "    size = 0    #初始化已下载大小\n",
    "    chunk_size = 1024  # 每次下载的数据大小\n",
    "    content_size = int(resp.headers['content-length'])  # 下载文件总大小\n",
    "    try:\n",
    "        if resp.status_code == 200:   #判断是否响应成功\n",
    "            print('Start download,[File size]:{size:.2f} MB'.format(size=content_size/chunk_size/1024))   #开始下载，显示下载文件大小\n",
    "            with open(file_path, 'wb') as file:   #显示进度条\n",
    "                for data in resp.iter_content(chunk_size=chunk_size):\n",
    "                    file.write(data)\n",
    "                    size += len(data)\n",
    "                    print('\\r'+'[下载进度]:%s%.2f%%' % ('>'*int(size*50/content_size), float(size/content_size*100)), end=' ')\n",
    "        end = time.time()   #下载结束时间\n",
    "        print('\\n'+'Download completed!,times: %.2f秒' % (end - start))  #输出下载用时时间\n",
    "    except ValueError:\n",
    "        print('Error!')\n",
    "    unzip_file_path = os.path.join(path, 'voc')\n",
    "    if not os.path.exists(unzip_file_path):   # 看是否有该文件夹，没有则创建文件夹\n",
    "        os.mkdir(unzip_file_path)\n",
    "    zip_file = zipfile.ZipFile(file_path)\n",
    "    zip_list = zip_file.namelist()  # 压缩文件清单，可以直接看到压缩包内的各个文件的明细\n",
    "    for f in zip_list:  # 遍历这些文件，逐个解压出来，\n",
    "        zip_file.extract(f, unzip_file_path)\n",
    "    zip_file.close()\n",
    "    print('Successfully unzip download flower dataset from website!')\n",
    "\n",
    "#下载地址\n",
    "url = 'https://git.openi.org.cn/attachments/7f8b0776-f287-4cc5-be34-b29f382383f9?type=0'\n",
    "download_and_unzip(url, os.path.join(os.getcwd(), 'dataset'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c102e028",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 数据格式转换\n",
    "\n",
    "+ 将voc数据集中的**xml格式的图像标注信息转换成为字典的形式**，为后续数据集读取做准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b46cc72",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#VOC21个类别标签名（包括背景）\n",
    "classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8251fc0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et\n",
    "#使用Element表示xml中的节点、文本、注释\n",
    "import os\n",
    "\n",
    "data_path = './dataset/voc/VOC'\n",
    "voc_json = 'pascal_voc_classes.json'\n",
    "\n",
    "def get_imageId_from_fileName(filename, id_iter):\n",
    "    \"\"\"Get imageID from fileName if fileName is int, else return id_iter.\"\"\"\n",
    "    filename = os.path.splitext(filename)[0]\n",
    "    if filename.isdigit():\n",
    "        return int(filename)\n",
    "    return id_iter\n",
    "\n",
    "def create_voc_label(is_training):\n",
    "    \"\"\"Get image path and annotation from VOC.\"\"\"\n",
    "    voc_root = data_path\n",
    "    cls_map = {name: i for i, name in enumerate(classes)}\n",
    "    sub_dir = 'train' if is_training else 'eval'\n",
    "    voc_dir = os.path.join(voc_root, sub_dir)\n",
    "    if not os.path.isdir(voc_dir):\n",
    "        raise ValueError(f'Cannot find {sub_dir} dataset path.')\n",
    "\n",
    "    image_dir = anno_dir = voc_dir\n",
    "    if os.path.isdir(os.path.join(voc_dir, 'Images')):\n",
    "        image_dir = os.path.join(voc_dir, 'Images')\n",
    "    if os.path.isdir(os.path.join(voc_dir, 'Annotations')):\n",
    "        anno_dir = os.path.join(voc_dir, 'Annotations')\n",
    "\n",
    "    if not is_training:\n",
    "        json_file = os.path.join(voc_root, voc_json)\n",
    "        file_dir = os.path.split(json_file)[0]\n",
    "        if not os.path.isdir(file_dir):\n",
    "            os.makedirs(file_dir)\n",
    "        json_dict = {\"images\": [], \"type\": \"instances\", \"annotations\": [],\n",
    "                     \"categories\": []}\n",
    "        bnd_id = 1\n",
    "\n",
    "    image_files_dict = {}\n",
    "    image_anno_dict = {}\n",
    "    images = []\n",
    "    id_iter = 0\n",
    "    for anno_file in os.listdir(anno_dir):\n",
    "        print(anno_file)\n",
    "        if not anno_file.endswith('xml'):\n",
    "            continue\n",
    "        tree = et.parse(os.path.join(anno_dir, anno_file))\n",
    "        root_node = tree.getroot()\n",
    "        file_name = root_node.find('filename').text\n",
    "        img_id = get_imageId_from_fileName(file_name, id_iter)\n",
    "        id_iter += 1\n",
    "        image_path = os.path.join(image_dir, file_name)\n",
    "        print(image_path)\n",
    "        if not os.path.isfile(image_path):\n",
    "            print(f'Cannot find image {file_name} according to annotations.')\n",
    "            continue\n",
    "\n",
    "        labels = []\n",
    "        for obj in root_node.iter('object'):\n",
    "            cls_name = obj.find('name').text\n",
    "            if cls_name not in cls_map:\n",
    "                print(f'Label \"{cls_name}\" not in \"{classes}\"')\n",
    "                continue\n",
    "            bnd_box = obj.find('bndbox')\n",
    "            x_min = int(float(bnd_box.find('xmin').text)) - 1\n",
    "            y_min = int(float(bnd_box.find('ymin').text)) - 1\n",
    "            x_max = int(float(bnd_box.find('xmax').text)) - 1\n",
    "            y_max = int(float(bnd_box.find('ymax').text)) - 1\n",
    "            labels.append([y_min, x_min, y_max, x_max, cls_map[cls_name]])\n",
    "\n",
    "            if not is_training:\n",
    "                o_width = abs(x_max - x_min)\n",
    "                o_height = abs(y_max - y_min)\n",
    "                ann = {'area': o_width * o_height, 'iscrowd': 0, 'image_id': \\\n",
    "                    img_id, 'bbox': [x_min, y_min, o_width, o_height], \\\n",
    "                       'category_id': cls_map[cls_name], 'id': bnd_id, \\\n",
    "                       'ignore': 0, \\\n",
    "                       'segmentation': []}\n",
    "                json_dict['annotations'].append(ann)\n",
    "                bnd_id = bnd_id + 1\n",
    "\n",
    "        if labels:\n",
    "            images.append(img_id)\n",
    "            image_files_dict[img_id] = image_path\n",
    "            image_anno_dict[img_id] = np.array(labels)\n",
    "\n",
    "        if not is_training:\n",
    "            size = root_node.find(\"size\")\n",
    "            width = int(size.find('width').text)\n",
    "            height = int(size.find('height').text)\n",
    "            image = {'file_name': file_name, 'height': height, 'width': width,\n",
    "                     'id': img_id}\n",
    "            json_dict['images'].append(image)\n",
    "\n",
    "    if not is_training:\n",
    "        for cls_name, cid in cls_map.items():\n",
    "            cat = {'supercategory': 'none', 'id': cid, 'name': cls_name}\n",
    "            json_dict['categories'].append(cat)\n",
    "        json_fp = open(json_file, 'w')\n",
    "        json_str = json.dumps(json_dict)\n",
    "        json_fp.write(json_str)\n",
    "        json_fp.close()\n",
    "\n",
    "\n",
    "    return images, image_files_dict, image_anno_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f0a8bc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ 用FileWriter API将**数据转换成MindRecord格式**。需要注意的是**生成MindRecord文件后，如果修改文件名，可能会导致读取文件失败**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a54ea1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mindspore.mindrecord import FileWriter\n",
    "#将用户自定义的数据转为MindRecord格式的数据集\n",
    "\n",
    "def voc_data_to_mindrecord(mindrecord_dir, is_training, prefix=\"ssd.mindrecord\", file_num=8):\n",
    "    \"\"\"Create MindRecord file by image_dir and anno_path.\"\"\"\n",
    "    mindrecord_path = os.path.join(mindrecord_dir, prefix)\n",
    "    writer = FileWriter(mindrecord_path, file_num)\n",
    "    images, image_path_dict, image_anno_dict = create_voc_label(is_training)\n",
    "\n",
    "    ssd_json = {\n",
    "        \"img_id\": {\"type\": \"int32\", \"shape\": [1]},\n",
    "        \"image\": {\"type\": \"bytes\"},\n",
    "        \"annotation\": {\"type\": \"int32\", \"shape\": [-1, 5]},\n",
    "    }\n",
    "    writer.add_schema(ssd_json, \"ssd_json\")\n",
    "\n",
    "    for img_id in images:\n",
    "        image_path = image_path_dict[img_id]\n",
    "        with open(image_path, 'rb') as f:\n",
    "            img = f.read()\n",
    "        annos = np.array(image_anno_dict[img_id], dtype=np.int32)\n",
    "        img_id = np.array([img_id], dtype=np.int32)\n",
    "        row = {\"img_id\": img_id, \"image\": img, \"annotation\": annos}\n",
    "        writer.write_raw_data([row])\n",
    "    writer.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25674d8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ **创建MindRecord格式的数据集**，并生成MindRecord文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe25c964",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_mindrecord(dataset=\"voc\", prefix=\"ssd.mindrecord\", is_training=True):\n",
    "    print(\"Start create dataset!\")\n",
    "\n",
    "    # It will generate mindrecord file in config.mindrecord_dir,\n",
    "    # and the file name is ssd.mindrecord0, 1, ... file_num.\n",
    "\n",
    "    mindrecord_dir = data_path\n",
    "    print(mindrecord_dir)\n",
    "    mindrecord_file = os.path.join(mindrecord_dir, prefix + \"0\")\n",
    "    if not os.path.exists(mindrecord_file):\n",
    "        if not os.path.isdir(mindrecord_dir):\n",
    "            os.makedirs(mindrecord_dir)\n",
    "        if dataset == \"voc\":\n",
    "            voc_root = data_path\n",
    "            if os.path.isdir(voc_root):\n",
    "                print(\"Create Mindrecord.\")\n",
    "                voc_data_to_mindrecord(mindrecord_dir, is_training, prefix)\n",
    "                print(\"Create Mindrecord Done, at {}\".format(mindrecord_dir))\n",
    "            else:\n",
    "                print(\"voc_root not exits.\")\n",
    "        else:\n",
    "            if os.path.isdir(config.image_dir) and os.path.exists(config.anno_path):\n",
    "                print(\"Create Mindrecord.\")\n",
    "                data_to_mindrecord_byte_image(\"other\", is_training, prefix)\n",
    "                print(\"Create Mindrecord Done, at {}\".format(mindrecord_dir))\n",
    "            else:\n",
    "                print(\"image_dir or anno_path not exits.\")\n",
    "    return mindrecord_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359b84d0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 加载数据集\n",
    "\n",
    "+ 使用MindDataset API**加载MindRecord格式数据集**，读取和解析MindRecord数据文件构建数据集。生成的数据集的列名和列类型取决于MindRecord文件中的保存的列名与类型。\n",
    "\n",
    "+ 进行**数据增强**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "487f16bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def intersect(box_a, box_b):\n",
    "    \"\"\"Compute the intersect of two sets of boxes.\"\"\"\n",
    "    max_yx = np.minimum(box_a[:, 2:4], box_b[2:4])\n",
    "    min_yx = np.maximum(box_a[:, :2], box_b[:2])\n",
    "    inter = np.clip((max_yx - min_yx), a_min=0, a_max=np.inf)\n",
    "    return inter[:, 0] * inter[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05fb327a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#计算交并比\n",
    "\n",
    "def jaccard_numpy(box_a, box_b):\n",
    "    \"\"\"Compute the jaccard overlap of two sets of boxes.\"\"\"\n",
    "    inter = intersect(box_a, box_b)\n",
    "    area_a = ((box_a[:, 2] - box_a[:, 0]) *\n",
    "              (box_a[:, 3] - box_a[:, 1]))\n",
    "    area_b = ((box_b[2] - box_b[0]) *\n",
    "              (box_b[3] - box_b[1]))\n",
    "    union = area_a + area_b - inter\n",
    "    return inter / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "542bac92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _rand(a=0., b=1.):\n",
    "    \"\"\"Generate random.\"\"\"\n",
    "    return np.random.rand() * (b - a) + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30a56257",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#随机裁剪\n",
    "\n",
    "def random_sample_crop(image, boxes):\n",
    "    \"\"\"Random Crop the image and boxes\"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    min_iou = np.random.choice([None, 0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "\n",
    "    if min_iou is None:\n",
    "        return image, boxes\n",
    "\n",
    "    # max trails (50)\n",
    "    for _ in range(50):\n",
    "        image_t = image\n",
    "\n",
    "        w = _rand(0.3, 1.0) * width\n",
    "        h = _rand(0.3, 1.0) * height\n",
    "\n",
    "        # aspect ratio constraint b/t .5 & 2\n",
    "        if h / w < 0.5 or h / w > 2:\n",
    "            continue\n",
    "\n",
    "        left = _rand() * (width - w)\n",
    "        top = _rand() * (height - h)\n",
    "\n",
    "        rect = np.array([int(top), int(left), int(top + h), int(left + w)])\n",
    "        overlap = jaccard_numpy(boxes, rect)\n",
    "\n",
    "        # dropout some boxes\n",
    "        drop_mask = overlap > 0\n",
    "        if not drop_mask.any():\n",
    "            continue\n",
    "\n",
    "        if overlap[drop_mask].min() < min_iou and overlap[drop_mask].max() > (min_iou + 0.2):\n",
    "            continue\n",
    "\n",
    "        image_t = image_t[rect[0]:rect[2], rect[1]:rect[3], :]\n",
    "\n",
    "        centers = (boxes[:, :2] + boxes[:, 2:4]) / 2.0\n",
    "\n",
    "        m1 = (rect[0] < centers[:, 0]) * (rect[1] < centers[:, 1])\n",
    "        m2 = (rect[2] > centers[:, 0]) * (rect[3] > centers[:, 1])\n",
    "\n",
    "        # mask in that both m1 and m2 are true\n",
    "        mask = m1 * m2 * drop_mask\n",
    "\n",
    "        # have any valid boxes? try again if not\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        # take only matching gt boxes\n",
    "        boxes_t = boxes[mask, :].copy()\n",
    "\n",
    "        boxes_t[:, :2] = np.maximum(boxes_t[:, :2], rect[:2])\n",
    "        boxes_t[:, :2] -= rect[:2]\n",
    "        boxes_t[:, 2:4] = np.minimum(boxes_t[:, 2:4], rect[2:4])\n",
    "        boxes_t[:, 2:4] -= rect[:2]\n",
    "\n",
    "        return image_t, boxes_t\n",
    "    return image, boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec715698",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 生成默认框\n",
    "\n",
    "+ 在每个预测特征层的每个cell上都会生成默认框\n",
    "\n",
    "+ 每个预测特征层上的默认框的尺寸以及数量设置如下表所示，表中$1:1$、$1:2$、$2:1$、$1:3$、$3:1$为默认框的比例，其中$1:1$的默认框会有两种尺寸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4df2a3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"./images/DefaultBox设置.png\" width=\"80%\" height=\"60%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad44fa1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ 默认框尺寸的计算公式如下：\n",
    "\n",
    " $$s_k=s_{min} +\\frac{s_{max}-s_{min}}{m-1}{(k-1)}，k\\in[1,m]$$\n",
    "\n",
    "+ 本次实验中最小尺寸设置为$0.2$，最大尺寸设置为$0.95$，$m$为使用的特征图的个数，**SSD300中$m$为6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daa704a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "#迭代器模块导入\n",
    "import math\n",
    "\n",
    "#num_ssd_boxes = num_default×对应的特征图的大小\n",
    "num_ssd_boxes = 1917\n",
    "\n",
    "#特征图向原图映射的步长\n",
    "steps = [16, 32, 64, 100, 150, 300]\n",
    "#输入图像尺寸\n",
    "img_shape = [300, 300]\n",
    "#交并比匹配阈值\n",
    "match_threshold = 0.5\n",
    "#默认框的最小与最大尺寸设置\n",
    "min_scale = 0.2\n",
    "max_scale = 0.95\n",
    "#每个预测层默认框的宽高比设置\n",
    "aspect_ratios = [[], [2, 3], [2, 3], [2, 3], [2, 3], [2, 3]]\n",
    "#在对应的预测特征层的每个cell生成的default box的数量\n",
    "num_default = [3, 6, 6, 6, 6, 6]\n",
    "#每个预测特征层对应的输出特征图尺寸\n",
    "feature_sizes = [19, 10, 5, 3, 2, 1]\n",
    "\n",
    "class GeneratDefaultBoxes():\n",
    "    \"\"\"\n",
    "    Generate Default boxes for SSD, follows the order of (W, H, archor_sizes).\n",
    "    `self.default_boxes` has a shape of [archor_sizes, H, W, 4], the last dimension is [y, x, h, w].\n",
    "    `self.default_boxes_tlbr` has a shape as `self.default_boxes`, the last dimension is [y1, x1, y2, x2].\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        fk = img_shape[0] / np.array(steps)                              #fk为第k个特征图尺寸大小\n",
    "        scale_rate = (max_scale - min_scale) / (len(num_default) - 1)\n",
    "        scales = [min_scale + scale_rate * i for i in range(len(num_default))] + [1.0]\n",
    "        self.default_boxes = []\n",
    "        for idex, feature_size in enumerate(feature_sizes):\n",
    "            sk1 = scales[idex]\n",
    "            sk2 = scales[idex + 1]\n",
    "            sk3 = math.sqrt(sk1 * sk2)\n",
    "            if idex == 0 and not aspect_ratios[idex]:\n",
    "                w, h = sk1 * math.sqrt(2), sk1 / math.sqrt(2)\n",
    "                all_sizes = [(0.1, 0.1), (w, h), (h, w)]\n",
    "            else:\n",
    "                all_sizes = [(sk1, sk1)]\n",
    "                for aspect_ratio in aspect_ratios[idex]:\n",
    "                    w, h = sk1 * math.sqrt(aspect_ratio), sk1 / math.sqrt(aspect_ratio)\n",
    "                    all_sizes.append((w, h))\n",
    "                    all_sizes.append((h, w))\n",
    "                all_sizes.append((sk3, sk3))\n",
    "\n",
    "            assert len(all_sizes) == num_default[idex]\n",
    "\n",
    "            #计算默认框相对于当前特征图的中心坐标，i为行，j为列\n",
    "            for i, j in it.product(range(feature_size), repeat=2):\n",
    "                for w, h in all_sizes:\n",
    "                    cx, cy = (j + 0.5) / fk[idex], (i + 0.5) / fk[idex]\n",
    "                    self.default_boxes.append([cy, cx, h, w])\n",
    "\n",
    "        #将所有默认框(cy,cx,h,w)转换为(ymin,xmin,ymax,xmax)的形式，即左上和右下点坐标\n",
    "        def to_tlbr(cy, cx, h, w):\n",
    "            return cy - h / 2, cx - w / 2, cy + h / 2, cx + w / 2\n",
    "\n",
    "        # For IoU calculation\n",
    "        self.default_boxes_tlbr = np.array(tuple(to_tlbr(*i) for i in self.default_boxes), dtype='float32')\n",
    "        self.default_boxes = np.array(self.default_boxes, dtype='float32')\n",
    "\n",
    "default_boxes_tlbr = GeneratDefaultBoxes().default_boxes_tlbr\n",
    "default_boxes = GeneratDefaultBoxes().default_boxes\n",
    "y1, x1, y2, x2 = np.split(default_boxes_tlbr[:, :4], 4, axis=-1)\n",
    "vol_anchors = (x2 - x1) * (y2 - y1)\n",
    "matching_threshold = match_threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f2e103",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 正负样本匹配\n",
    "\n",
    "匹配准则：\n",
    "\n",
    "+ (1)选择与Ground Truth交并比最大的默认框所对应的IOU值；\n",
    "\n",
    "+ (2)将与当前标注信息中的每个Ground Truth交并比最大的默认框所对应的IOU值置为2，即选为正样本。若不进行这一步，将会有Ground Truth未匹配到默认框；\n",
    "\n",
    "+ (3)将与Ground Truth交并比大于0.5的默认框也置为正样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83b1f1fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prior_scaling = [0.1, 0.2]\n",
    "\n",
    "#输入GT框的坐标信息bbox[0]-bbox[3]与标签信息bbox[4]\n",
    "def ssd_bboxes_encode(boxes):\n",
    "    \"\"\"\n",
    "    Labels anchors with ground truth inputs.\n",
    "\n",
    "    Args:\n",
    "        boxex: ground truth with shape [N, 5], for each row, it stores [y, x, h, w, cls].\n",
    "\n",
    "    Returns:\n",
    "        gt_loc: location ground truth with shape [num_anchors, 4].\n",
    "        gt_label: class ground truth with shape [num_anchors, 1].\n",
    "        num_matched_boxes: number of positives in an image.\n",
    "    \"\"\"\n",
    "\n",
    "    #计算每个默认框与当前图片标注信息的每个GT的最大交并比\n",
    "    def jaccard_with_anchors(bbox):\n",
    "        \"\"\"Compute jaccard score a box and the anchors.\"\"\"\n",
    "        # Intersection bbox and volume.\n",
    "        ymin = np.maximum(y1, bbox[0])\n",
    "        xmin = np.maximum(x1, bbox[1])\n",
    "        ymax = np.minimum(y2, bbox[2])\n",
    "        xmax = np.minimum(x2, bbox[3])\n",
    "        w = np.maximum(xmax - xmin, 0.)\n",
    "        h = np.maximum(ymax - ymin, 0.)\n",
    "\n",
    "        # Volumes.\n",
    "        inter_vol = h * w\n",
    "        union_vol = vol_anchors + (bbox[2] - bbox[0]) * (bbox[3] - bbox[1]) - inter_vol\n",
    "        jaccard = inter_vol / union_vol\n",
    "        return np.squeeze(jaccard)\n",
    "\n",
    "    pre_scores = np.zeros((num_ssd_boxes), dtype=np.float32)    ##pre_scores用于存放默认框匹配的Ground Truth的交并比\n",
    "    t_boxes = np.zeros((num_ssd_boxes, 4), dtype=np.float32)    #t_boxes用于存放与默认框匹配的Ground Truth的坐标信息\n",
    "    t_label = np.zeros((num_ssd_boxes), dtype=np.int64)         #t_label用于存放默认框匹配的Ground Truth的标签信息\n",
    "    for bbox in boxes:\n",
    "        label = int(bbox[4])\n",
    "        scores = jaccard_with_anchors(bbox)\n",
    "        idx = np.argmax(scores)              #选取与当前GT交并比最大的默认框的索引值\n",
    "        scores[idx] = 2.0                    #将与当前GT交并比最大的默认框所对应的IOU值置为2.0\n",
    "        mask = (scores > matching_threshold) #将与GT交并比大于0.5的默认框均设置为正样本\n",
    "        mask = mask & (scores > pre_scores)  #交并比是否比之前匹配的Ground Truth大\n",
    "        pre_scores = np.maximum(pre_scores, scores * mask)  #所有正样本的交并比分数\n",
    "        t_label = mask * label + (1 - mask) * t_label      #将正样本所对应的标签信息导出\n",
    "        for i in range(4):\n",
    "            t_boxes[:, i] = mask * bbox[i] + (1 - mask) * t_boxes[:, i]   #将正样本对应的Ground Truth坐标信息导出\n",
    "\n",
    "    index = np.nonzero(t_label)  #存放与Ground Truth匹配的默认框的索引值，即哪个默认框与Ground Truth匹配\n",
    "\n",
    "    # Transform to tlbr.  将(ymin,xmin,ymax,xmax)转换为(cy,cx,h,w)格式\n",
    "    bboxes = np.zeros((num_ssd_boxes, 4), dtype=np.float32)           #bboxes用于存放已与默认框匹配的Ground Truth的坐标信息\n",
    "    bboxes[:, [0, 1]] = (t_boxes[:, [0, 1]] + t_boxes[:, [2, 3]]) / 2\n",
    "    bboxes[:, [2, 3]] = t_boxes[:, [2, 3]] - t_boxes[:, [0, 1]]\n",
    "\n",
    "    # Encode features.\n",
    "    bboxes_t = bboxes[index]\n",
    "    default_boxes_t = default_boxes[index]\n",
    "    #切片操作，计算所有的默认框与其匹配到的Ground Truth中心坐标偏差\n",
    "    bboxes_t[:, :2] = (bboxes_t[:, :2] - default_boxes_t[:, :2]) / (default_boxes_t[:, 2:] * prior_scaling[0])\n",
    "    tmp = np.maximum(bboxes_t[:, 2:4] / default_boxes_t[:, 2:4], 0.000001)\n",
    "    #计算宽高缩放损失\n",
    "    bboxes_t[:, 2:4] = np.log(tmp) / prior_scaling[1]\n",
    "    bboxes[index] = bboxes_t\n",
    "    #记录正样本个数\n",
    "    num_match = np.array([len(np.nonzero(t_label)[0])], dtype=np.int32)\n",
    "    return bboxes, t_label.astype(np.int32), num_match\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1572cdbc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3590ec9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#进行数据增强\n",
    "def preprocess_fn(img_id, image, box, is_training):\n",
    "    \"\"\"Preprocess function for dataset.\"\"\"\n",
    "    cv2.setNumThreads(2)\n",
    "\n",
    "    def _infer_data(image, input_shape):\n",
    "        img_h, img_w, _ = image.shape\n",
    "        input_h, input_w = input_shape\n",
    "\n",
    "        image = cv2.resize(image, (input_w, input_h))\n",
    "\n",
    "        # When the channels of image is 1\n",
    "        if len(image.shape) == 2:\n",
    "            image = np.expand_dims(image, axis=-1)\n",
    "            image = np.concatenate([image, image, image], axis=-1)\n",
    "\n",
    "        return img_id, image, np.array((img_h, img_w), np.float32)\n",
    "\n",
    "    def _data_aug(image, box, is_training, image_size=(300, 300)):\n",
    "        \"\"\"Data augmentation function.\"\"\"\n",
    "        ih, iw, _ = image.shape\n",
    "        h, w = image_size\n",
    "\n",
    "        if not is_training:\n",
    "            return _infer_data(image, image_size)\n",
    "\n",
    "        # Random crop\n",
    "        box = box.astype(np.float32)\n",
    "        image, box = random_sample_crop(image, box)\n",
    "        ih, iw, _ = image.shape\n",
    "\n",
    "        # Resize image\n",
    "        image = cv2.resize(image, (w, h))\n",
    "\n",
    "        # Flip image or not\n",
    "        flip = _rand() < .5\n",
    "        if flip:\n",
    "            image = cv2.flip(image, 1, dst=None)      #水平翻转\n",
    "\n",
    "        # When the channels of image is 1\n",
    "        if len(image.shape) == 2:\n",
    "            image = np.expand_dims(image, axis=-1)\n",
    "            image = np.concatenate([image, image, image], axis=-1)\n",
    "\n",
    "        box[:, [0, 2]] = box[:, [0, 2]] / ih\n",
    "        box[:, [1, 3]] = box[:, [1, 3]] / iw\n",
    "\n",
    "        if flip:\n",
    "            box[:, [1, 3]] = 1 - box[:, [3, 1]]\n",
    "\n",
    "        box, label, num_match = ssd_bboxes_encode(box)\n",
    "        return image, box, label, num_match\n",
    "\n",
    "    return _data_aug(image, box, is_training, image_size=[300, 300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3808f8d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import mindspore.dataset as de\n",
    "\n",
    "#加载数据\n",
    "def create_ssd_dataset(mindrecord_file, batch_size=1, device_num=1, rank=0,\n",
    "                       is_training=True, num_parallel_workers=4, use_multiprocessing=True):\n",
    "    \"\"\"Create SSD dataset with MindDataset.\"\"\"\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    if cores < num_parallel_workers:\n",
    "        print(\"The num_parallel_workers {} is set too large, now set it {}\".format(num_parallel_workers, cores))\n",
    "        num_parallel_workers = cores\n",
    "    ##读取和解析MindRecord数据文件构建数据集\n",
    "    ds = de.MindDataset(mindrecord_file, columns_list=[\"img_id\", \"image\", \"annotation\"], num_shards=device_num,\n",
    "                        shard_id=rank, num_parallel_workers=num_parallel_workers, shuffle=is_training)\n",
    "    #将输入的压缩图像解码为RGB格式\n",
    "    decode = de.vision.c_transforms.Decode()\n",
    "    #给定一组数据增强列表，按顺序将数据增强作用在数据集对象上\n",
    "    ds = ds.map(operations=decode, input_columns=[\"image\"])\n",
    "    #将输入图像的shape从 <H, W, C> 转换为 <C, H, W>\n",
    "    change_swap_op = de.vision.c_transforms.HWC2CHW()\n",
    "    #根据均值和标准差对输入图像进行归一化\n",
    "    normalize_op = de.vision.c_transforms.Normalize(mean=[0.485 * 255, 0.456 * 255, 0.406 * 255], std=[0.229 * 255, 0.224 * 255, 0.225 * 255])\n",
    "    #随机调整输入图像的亮度、对比度、饱和度和色调。\n",
    "    color_adjust_op = de.vision.c_transforms.RandomColorAdjust(brightness=0.4, contrast=0.4, saturation=0.4)\n",
    "    compose_map_func = (lambda img_id, image, annotation: preprocess_fn(img_id, image, annotation, is_training))\n",
    "    if is_training:\n",
    "        output_columns = [\"image\", \"box\", \"label\", \"num_match\"]\n",
    "        trans = [color_adjust_op, normalize_op, change_swap_op]\n",
    "    else:\n",
    "        output_columns = [\"img_id\", \"image\", \"image_shape\"]\n",
    "        trans = [normalize_op, change_swap_op]\n",
    "    ds = ds.map(operations=compose_map_func, input_columns=[\"img_id\", \"image\", \"annotation\"],\n",
    "                output_columns=output_columns, column_order=output_columns,\n",
    "                python_multiprocessing=use_multiprocessing,\n",
    "                num_parallel_workers=num_parallel_workers)\n",
    "    ds = ds.map(operations=trans, input_columns=[\"image\"], python_multiprocessing=use_multiprocessing,\n",
    "                num_parallel_workers=num_parallel_workers)\n",
    "    #将数据集中连续 batch_size 条数据合并为一个批处理数据\n",
    "    #当最后一个批处理数据包含的数据条目小于 batch_size 时，将该批处理丢弃，不传递给下一个操作\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cd9e16a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start create dataset!\n",
      "./dataset/voc/VOC\n",
      "Create dataset done! dataset size is 11988\n"
     ]
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "\n",
    "rank = 0\n",
    "device_num = 1\n",
    "device_target = \"CPU\"\n",
    "loss_scale = 1.0\n",
    "ms.context.set_context(mode=ms.context.GRAPH_MODE, device_target=\"CPU\")\n",
    "\n",
    "mindrecord_file = create_mindrecord(\"voc\", \"ssd.mindrecord\", True)\n",
    "\n",
    "# When create MindDataset, using the fitst mindrecord file, such as ssd.mindrecord0.\n",
    "use_multiprocessing = (device_target != \"CPU\")\n",
    "dataset = create_ssd_dataset(mindrecord_file, batch_size=1, device_num=device_num, rank=rank, use_multiprocessing=use_multiprocessing)\n",
    "\n",
    "dataset_size = dataset.get_dataset_size()\n",
    "print(f\"Create dataset done! dataset size is {dataset_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68faf5d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SSD模型搭建\n",
    "\n",
    "### Backbone部分\n",
    "\n",
    "采用[MobileNetV2](https://openaccess.thecvf.com/content_cvpr_2018/papers/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.pdf) 作为backbone进行特征提取\n",
    "\n",
    "+ 首先搭建带BatchNormalization以及ReLU6激活函数的卷积层\n",
    "\n",
    "+ 注意：在ConvBNReLU层中**group参数**为1时为普通卷积操作，group参数为输入特征图通道数时为深度可分离卷积操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b166b91",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "\n",
    "def _bn(channel):\n",
    "    return nn.BatchNorm2d(channel, eps=1e-3, momentum=0.97,\n",
    "                          gamma_init=1, beta_init=0, moving_mean_init=0, moving_var_init=1)\n",
    "\n",
    "def _conv2d(in_channel, out_channel, kernel_size=3, stride=1, pad_mod='same'):\n",
    "    return nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride,\n",
    "                     padding=0, pad_mode=pad_mod, has_bias=True)\n",
    "\n",
    "class ConvBNReLU(nn.Cell):\n",
    "    \"\"\"\n",
    "    Convolution/Depthwise fused with Batchnorm and ReLU block definition.\n",
    "\n",
    "    Args:\n",
    "        in_planes (int): Input channel.\n",
    "        out_planes (int): Output channel.\n",
    "        kernel_size (int): Input kernel size.\n",
    "        stride (int): Stride size for the first convolutional layer. Default: 1.\n",
    "        groups (int): channel group. Convolution is 1 while Depthiwse is input channel. Default: 1.\n",
    "        shared_conv(Cell): Use the weight shared conv, default: None.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> ConvBNReLU(16, 256, kernel_size=1, stride=1, groups=1)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1, shared_conv=None):\n",
    "        super(ConvBNReLU, self).__init__()\n",
    "        padding = 0\n",
    "        in_channels = in_planes\n",
    "        out_channels = out_planes\n",
    "        if shared_conv is None:\n",
    "            if groups == 1:\n",
    "                conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, pad_mode='same', padding=padding)\n",
    "            else:\n",
    "                out_channels = in_planes\n",
    "                conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, pad_mode='same',\n",
    "                                 padding=padding, group=in_channels)\n",
    "            layers = [conv, _bn(out_planes), nn.ReLU6()]\n",
    "        else:\n",
    "            layers = [shared_conv, _bn(out_planes), nn.ReLU6()]\n",
    "        self.features = nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        output = self.features(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd999f4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "定义[MobileNetV2](https://openaccess.thecvf.com/content_cvpr_2018/papers/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.pdf) 的**反向残差结构**（反向残差结构如下图所示，(a)为残差结构，(b)为反向残差结构）\n",
    "\n",
    "反向残差结构\n",
    "\n",
    "+ 先通过一个$1×1$的普通卷积将$h×w×d$大小的特征图升维得到$h×w×td$大小的特征图，$t$对应代码中的扩展因子(expand_ratio)参数\n",
    "\n",
    "+ 再通过$3×3$的深度方向的卷积(Depthwise Convolution)操作，所得到的特征图大小为 $\\frac{h}{s}×\\frac{w}{s}×td$\n",
    "\n",
    "+ 最后通过$1×1$的点卷积(Pointwise Convolution)降维，此时使用的激活函数不是ReLU6激活函数，而是线性激活函数\n",
    "\n",
    "反向残差结构中只有**当步距(stride=1)，且输入与输出特征维度相同时**，会有和残差结构中的**shortcut连接**\n",
    "\n",
    "当**扩展因子为1**时，反向残差结构**第一层没有$1×1$的普通卷积**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e2e25",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"./images/backbone_反残差结构.png\" width=\"60%\" height=\"60%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ac6c7a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class InvertedResidual(nn.Cell):\n",
    "    \"\"\"\n",
    "    Residual block definition.\n",
    "\n",
    "    Args:\n",
    "        inp (int): Input channel.\n",
    "        oup (int): Output channel.\n",
    "        stride (int): Stride size for the first convolutional layer. Default: 1.\n",
    "        expand_ratio (int): expand ration of input channel\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> ResidualBlock(3, 256, 1, 1)\n",
    "    \"\"\"\n",
    "    def __init__(self, inp, oup, stride, expand_ratio, last_relu=False):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = int(round(inp * expand_ratio))\n",
    "        self.use_res_connect = stride == 1 and inp == oup\n",
    "\n",
    "        layers = []\n",
    "        if expand_ratio != 1:\n",
    "            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1))\n",
    "        layers.extend([\n",
    "            # Depthwise Convolution\n",
    "            ConvBNReLU(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim),\n",
    "            # Pointwise Convolution\n",
    "            nn.Conv2d(hidden_dim, oup, kernel_size=1, stride=1, has_bias=False),\n",
    "            _bn(oup),\n",
    "        ])\n",
    "        self.conv = nn.SequentialCell(layers)\n",
    "        self.cast = ops.Cast()\n",
    "        self.last_relu = last_relu\n",
    "        self.relu = nn.ReLU6()\n",
    "\n",
    "    def construct(self, x):\n",
    "        identity = x\n",
    "        x = self.conv(x)\n",
    "        if self.use_res_connect:\n",
    "            x = identity + x\n",
    "        if self.last_relu:\n",
    "            x = self.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd01e89e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "搭建MobileNetV2网络结构\n",
    "\n",
    "+ **_make_divisible函数将卷积核个数调整为round_nearest的整数倍**，这样操作对硬件友好\n",
    "\n",
    "下图为MobileNetV2网络结构示意图，图中$t$为扩展因子，$c$为输出特征图深度，$n$为反向残差块重复次数，$s$为每个反向残差层中第一个反向残差块的步距\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"./images/BackBone_MobileNetV2.png\" width=\"40%\" height=\"30%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9fe61d7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"nsures that all layers have a channel number that is divisible by 8.\"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "class SSDWithMobileNetV2(nn.Cell):\n",
    "    \"\"\"\n",
    "    MobileNetV2 architecture for SSD backbone.\n",
    "\n",
    "    Args:\n",
    "        width_mult (int): Channels multiplier for round to 8/16 and others. Default is 1.\n",
    "        inverted_residual_setting (list): Inverted residual settings. Default is None\n",
    "        round_nearest (list): Channel round to. Default is 8\n",
    "    Returns:\n",
    "        Tensor, the 13th feature after ConvBNReLU in MobileNetV2.\n",
    "        Tensor, the last feature in MobileNetV2.\n",
    "\n",
    "    Examples:\n",
    "        >>> SSDWithMobileNetV2()\n",
    "    \"\"\"\n",
    "    def __init__(self, width_mult=1.0, inverted_residual_setting=None, round_nearest=8):\n",
    "        super(SSDWithMobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32          #第一层卷积层输出特征图深度\n",
    "        last_channel = 1280         #最后一层输出特征图深度\n",
    "\n",
    "        if inverted_residual_setting is None:\n",
    "            inverted_residual_setting = [\n",
    "                # t, c, n, s\n",
    "                [1, 16, 1, 1],\n",
    "                [6, 24, 2, 2],\n",
    "                [6, 32, 3, 2],\n",
    "                [6, 64, 4, 2],\n",
    "                [6, 96, 3, 1],\n",
    "                [6, 160, 3, 2],\n",
    "                [6, 320, 1, 1],\n",
    "            ]\n",
    "        if len(inverted_residual_setting[0]) != 4:\n",
    "            raise ValueError(\"inverted_residual_setting should be non-empty \"\n",
    "                             \"or a 4-element list, got {}\".format(inverted_residual_setting))\n",
    "\n",
    "        #building first layer\n",
    "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
    "        self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
    "        features = [ConvBNReLU(3, input_channel, stride=2)]\n",
    "        # building inverted residual blocks\n",
    "        layer_index = 0\n",
    "        for t, c, n, s in inverted_residual_setting:\n",
    "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
    "            for i in range(n):\n",
    "                if layer_index == 13:\n",
    "                    hidden_dim = int(round(input_channel * t))\n",
    "                    self.expand_layer_conv_13 = ConvBNReLU(input_channel, hidden_dim, kernel_size=1)     #该层将作为SSD网络的Feature Map1\n",
    "                stride = s if i == 0 else 1\n",
    "                features.append(block(input_channel, output_channel, stride, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "                layer_index += 1\n",
    "        # building last several layers\n",
    "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1))\n",
    "\n",
    "        self.features_1 = nn.SequentialCell(features[:14])\n",
    "        self.features_2 = nn.SequentialCell(features[14:])\n",
    "\n",
    "    def construct(self, x):\n",
    "        out = self.features_1(x)\n",
    "        expand_layer_conv_13 = self.expand_layer_conv_13(out)\n",
    "        out = self.features_2(out)\n",
    "        return expand_layer_conv_13, out\n",
    "\n",
    "    def get_out_channels(self):\n",
    "        return self.last_channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df8009f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ssd_mobilenet_v2(**kwargs):\n",
    "    return SSDWithMobileNetV2(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e216e044",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "搭建后的Backbone部分结构框图如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996b666e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"./images/SSD_MobileNetV2_Backbone.png\" width=\"80%\" height=\"60%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b38f6b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 搭建SSD300网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed1f6dd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ 定义坐标回归参数与类别预测参数类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33007759",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mindspore.ops as ops\n",
    "\n",
    "class FlattenConcat(nn.Cell):\n",
    "    \"\"\"\n",
    "    Concatenate predictions into a single tensor.\n",
    "\n",
    "    Args:\n",
    "        config (dict): The default config of SSD.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, flatten predictions.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(FlattenConcat, self).__init__()\n",
    "        self.num_ssd_boxes = 1917\n",
    "        self.concat = ops.Concat(axis=1) #在指定轴上拼接输入Tensor\n",
    "        self.transpose = ops.Transpose() #根据指定的排列对输入的Tensor进行数据重排\n",
    "    def construct(self, inputs):\n",
    "        output = ()\n",
    "        batch_size = ops.shape(inputs[0])[0]\n",
    "        for x in inputs:\n",
    "            x = self.transpose(x, (0, 2, 3, 1))\n",
    "            output += (ops.reshape(x, (batch_size, -1)),)\n",
    "        res = self.concat(output)\n",
    "        return ops.reshape(res, (batch_size, self.num_ssd_boxes, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bed80a3f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _last_conv2d(in_channel, out_channel, kernel_size=3, stride=1, pad_mod='same', pad=0):\n",
    "    in_channels = in_channel\n",
    "    out_channels = in_channel\n",
    "    depthwise_conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, pad_mode='same',\n",
    "                               padding=pad, group=in_channels)\n",
    "    conv = _conv2d(in_channel, out_channel, kernel_size=1)\n",
    "    return nn.SequentialCell([depthwise_conv, _bn(in_channel), nn.ReLU6(), conv])\n",
    "\n",
    "#对Feature Map中的每个cell产生4×对应的default box个数的坐标回归参数，以及类别数×对应的default box个数的类别预测参数\n",
    "\n",
    "class MultiBox(nn.Cell):\n",
    "    \"\"\"\n",
    "    Multibox conv layers. Each multibox layer contains class conf scores and localization predictions.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, localization predictions.\n",
    "        Tensor, class conf scores.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MultiBox, self).__init__()\n",
    "        num_classes = 21\n",
    "        out_channels = [576, 1280, 512, 256, 256, 128]\n",
    "        num_default = [3, 6, 6, 6, 6, 6]\n",
    "\n",
    "        loc_layers = []\n",
    "        cls_layers = []\n",
    "        for k, out_channel in enumerate(out_channels):\n",
    "            loc_layers += [_last_conv2d(out_channel, 4 * num_default[k],\n",
    "                                        kernel_size=3, stride=1, pad_mod='same', pad=0)]\n",
    "            cls_layers += [_last_conv2d(out_channel, num_classes * num_default[k],\n",
    "                                        kernel_size=3, stride=1, pad_mod='same', pad=0)]\n",
    "\n",
    "        self.multi_loc_layers = nn.layer.CellList(loc_layers)\n",
    "        self.multi_cls_layers = nn.layer.CellList(cls_layers)\n",
    "        self.flatten_concat = FlattenConcat()\n",
    "\n",
    "    def construct(self, inputs):\n",
    "        loc_outputs = ()\n",
    "        cls_outputs = ()\n",
    "        for i in range(len(self.multi_loc_layers)):\n",
    "            loc_outputs += (self.multi_loc_layers[i](inputs[i]),)\n",
    "            cls_outputs += (self.multi_cls_layers[i](inputs[i]),)\n",
    "        return self.flatten_concat(loc_outputs), self.flatten_concat(cls_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dc5916",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ 将MobileNetV2的第12个输出大小为$14×14×96$的反向残差连接层截断，单独做一次`ConvBNReLU`卷积输出大小为$14×14×576$，将该输出特征图以及最后一层输出大小为$7×7×1280$的卷积层作为`Feature Map1、2`\n",
    "+ 再通过4个ConvBNReLU层生成`Feature Map3`至`Feature Map6`\n",
    "+ 将这6个预测特征层作坐标参数回归和类别预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aafea66",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"ssd300\"\n",
    "\n",
    "class SSD300(nn.Cell):\n",
    "    \"\"\"\n",
    "    SSD300 Network. Default backbone is resnet34.\n",
    "\n",
    "    Args:\n",
    "        backbone (Cell): Backbone Network.\n",
    "        config (dict): The default config of SSD.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, localization predictions.\n",
    "        Tensor, class conf scores.\n",
    "\n",
    "    Examples:backbone\n",
    "         SSD300(backbone=resnet34(num_classes=None),\n",
    "                config=config).\n",
    "    \"\"\"\n",
    "    def __init__(self, backbone, is_training=True):\n",
    "        super(SSD300, self).__init__()\n",
    "\n",
    "        self.backbone = backbone\n",
    "        in_channels = [256, 576, 1280, 512, 256, 256]\n",
    "        out_channels = [576, 1280, 512, 256, 256, 128]\n",
    "        ratios = [0.2, 0.2, 0.2, 0.25, 0.5, 0.25]\n",
    "        strides = [1, 1, 2, 2, 2, 2]\n",
    "        residual_list = []\n",
    "        for i in range(2, len(in_channels)):\n",
    "            residual = InvertedResidual(in_channels[i], out_channels[i], stride=strides[i],\n",
    "                                        expand_ratio=ratios[i], last_relu=True)\n",
    "            residual_list.append(residual)\n",
    "        self.multi_residual = nn.layer.CellList(residual_list)\n",
    "        self.multi_box = MultiBox()\n",
    "        self.is_training = is_training\n",
    "        if not is_training:\n",
    "            self.activation = ops.Sigmoid()\n",
    "\n",
    "    def construct(self, x):\n",
    "        layer_out_13, output = self.backbone(x)\n",
    "        multi_feature = (layer_out_13, output)\n",
    "        feature = output\n",
    "        for residual in self.multi_residual:\n",
    "            feature = residual(feature)\n",
    "            multi_feature += (feature,)\n",
    "        pred_loc, pred_label = self.multi_box(multi_feature)\n",
    "        if not self.is_training:\n",
    "            pred_label = self.activation(pred_label)\n",
    "        pred_loc = ops.cast(pred_loc, ms.float32)\n",
    "        pred_label = ops.cast(pred_label, ms.float32)\n",
    "        return pred_loc, pred_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d567dd77",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ 初始化网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00181c2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#初始化神经元参数,生成一个服从截断正态（高斯）分布的随机数组用于初始化Tensor\n",
    "from mindspore.common.initializer import initializer, TruncatedNormal\n",
    "\n",
    "def init_net_param(network, initialize_mode='TruncatedNormal'):\n",
    "    \"\"\"Init the parameters in net.\"\"\"\n",
    "    params = network.trainable_params()\n",
    "    for p in params:\n",
    "        if 'beta' not in p.name and 'gamma' not in p.name and 'bias' not in p.name:\n",
    "            if initialize_mode == 'TruncatedNormal':\n",
    "                p.set_data(initializer(TruncatedNormal(0.02), p.data.shape, p.data.dtype))\n",
    "            else:\n",
    "                p.set_data(initialize_mode, p.data.shape, p.data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "feb07b8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ssd_model_build():\n",
    "    if model_name == \"ssd300\":\n",
    "        backbone = ssd_mobilenet_v2()\n",
    "        ssd = SSD300(backbone=backbone)\n",
    "        init_net_param(ssd)\n",
    "    else:\n",
    "        raise ValueError(f'config.model: {model_name} is not supported')\n",
    "    return ssd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b7c099",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "+ 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20a8d79e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ssd = ssd_model_build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b248e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 损失函数设计\n",
    "\n",
    "本次实验分类损失部分采用[《Focal Loss for Dense Object Detection》](https://arxiv.org/pdf/1708.02002.pdf)中提出的**Focal Loss**\n",
    "\n",
    "+ 计算公式为：\n",
    "\n",
    "$$FL(p_t)=-\\alpha_t{(1-p_t)^\\gamma}{log(p_t)}$$\n",
    "\n",
    "+ 其中$\\alpha_t$为平衡正负样本因子，$\\gamma$为平衡难例因子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2bd882f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mindspore import Tensor\n",
    "import mindspore as ms\n",
    "\n",
    "#计算预测值与真实值之间的sigmoid交叉熵\n",
    "class SigmoidFocalClassificationLoss(nn.Cell):\n",
    "    \"\"\"\"\n",
    "    Sigmoid focal-loss for classification.\n",
    "\n",
    "    Args:\n",
    "        gamma (float): Hyper-parameter to balance the easy and hard examples. Default: 2.0\n",
    "        alpha (float): Hyper-parameter to balance the positive and negative example. Default: 0.25\n",
    "\n",
    "    Returns:\n",
    "        Tensor, the focal loss.\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=2.0, alpha=0.25):\n",
    "        super(SigmoidFocalClassificationLoss, self).__init__()\n",
    "        self.sigmiod_cross_entropy = ops.SigmoidCrossEntropyWithLogits()\n",
    "        self.sigmoid = ops.Sigmoid()\n",
    "        #次幂计算\n",
    "        self.pow = ops.Pow()\n",
    "        #返回一个one-hot类型的Tensor\n",
    "        self.onehot = ops.OneHot()\n",
    "        self.on_value = Tensor(1.0, ms.float32)\n",
    "        self.off_value = Tensor(0.0, ms.float32)\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def construct(self, logits, label):\n",
    "        label = self.onehot(label, ops.shape(logits)[-1], self.on_value, self.off_value)\n",
    "        sigmiod_cross_entropy = self.sigmiod_cross_entropy(logits, label)\n",
    "        sigmoid = self.sigmoid(logits)\n",
    "        #转换输入Tensor的数据类型\n",
    "        label = ops.cast(label, ms.float32)\n",
    "        p_t = label * sigmoid + (1 - label) * (1 - sigmoid)\n",
    "        modulating_factor = self.pow(1 - p_t, self.gamma)\n",
    "        alpha_weight_factor = label * self.alpha + (1 - label) * (1 - self.alpha)\n",
    "        focal_loss = modulating_factor * alpha_weight_factor * sigmiod_cross_entropy\n",
    "        return focal_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41c6c21f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SSDWithLossCell(nn.Cell):\n",
    "    \"\"\"\"\n",
    "    Provide SSD training loss through network.\n",
    "\n",
    "    Args:\n",
    "        network (Cell): The training network.\n",
    "        config (dict): SSD config.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, the loss of the network.\n",
    "    \"\"\"\n",
    "    def __init__(self, network):\n",
    "        super(SSDWithLossCell, self).__init__()\n",
    "        self.network = network\n",
    "        self.less = ops.Less()\n",
    "        self.tile = ops.Tile()\n",
    "        self.reduce_sum = ops.ReduceSum()\n",
    "        self.expand_dims = ops.ExpandDims()\n",
    "        self.class_loss = SigmoidFocalClassificationLoss(2.0, 0.75)\n",
    "        self.loc_loss = nn.SmoothL1Loss()\n",
    "\n",
    "    def construct(self, x, gt_loc, gt_label, num_matched_boxes):\n",
    "        pred_loc, pred_label = self.network(x)\n",
    "        mask = ops.cast(self.less(0, gt_label), ms.float32)\n",
    "        num_matched_boxes = self.reduce_sum(ops.cast(num_matched_boxes, ms.float32))\n",
    "\n",
    "        # Localization Loss\n",
    "        mask_loc = self.tile(self.expand_dims(mask, -1), (1, 1, 4))\n",
    "        smooth_l1 = self.loc_loss(pred_loc, gt_loc) * mask_loc\n",
    "        loss_loc = self.reduce_sum(self.reduce_sum(smooth_l1, -1), -1)\n",
    "\n",
    "        # Classification Loss\n",
    "        loss_cls = self.class_loss(pred_label, gt_label)\n",
    "        loss_cls = self.reduce_sum(loss_cls, (1, 2))\n",
    "\n",
    "        return self.reduce_sum((loss_cls + loss_loc) / num_matched_boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d1147ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net = SSDWithLossCell(ssd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f62fee6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ca662b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 本地训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ae56884",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def get_lr(global_step, lr_init, lr_end, lr_max, warmup_epochs, total_epochs, steps_per_epoch):\n",
    "    \"\"\"\n",
    "    generate learning rate array\n",
    "\n",
    "    Args:\n",
    "       global_step(int): total steps of the training\n",
    "       lr_init(float): init learning rate\n",
    "       lr_end(float): end learning rate\n",
    "       lr_max(float): max learning rate\n",
    "       warmup_epochs(float): number of warmup epochs\n",
    "       total_epochs(int): total epoch of training\n",
    "       steps_per_epoch(int): steps of one epoch\n",
    "\n",
    "    Returns:\n",
    "       np.array, learning rate array\n",
    "    \"\"\"\n",
    "    lr_each_step = []\n",
    "    total_steps = steps_per_epoch * total_epochs\n",
    "    warmup_steps = steps_per_epoch * warmup_epochs\n",
    "    for i in range(total_steps):\n",
    "        if i < warmup_steps:\n",
    "            lr = lr_init + (lr_max - lr_init) * i / warmup_steps\n",
    "        else:\n",
    "            lr = lr_end + \\\n",
    "                 (lr_max - lr_end) * \\\n",
    "                 (1. + math.cos(math.pi * (i - warmup_steps) / (total_steps - warmup_steps))) / 2.\n",
    "        if lr < 0.0:\n",
    "            lr = 0.0\n",
    "        lr_each_step.append(lr)\n",
    "\n",
    "    current_step = global_step\n",
    "    lr_each_step = np.array(lr_each_step).astype(np.float32)\n",
    "    learning_rate = lr_each_step[current_step:]\n",
    "\n",
    "    return learning_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bbb764e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mindspore.context import ParallelMode\n",
    "\n",
    "grad_scale = ops.MultitypeFuncGraph(\"grad_scale\")\n",
    "@grad_scale.register(\"Tensor\", \"Tensor\")\n",
    "def tensor_grad_scale(scale, grad):\n",
    "    return grad * ops.Reciprocal()(scale)\n",
    "\n",
    "class TrainingWrapper(nn.Cell):\n",
    "    \"\"\"\n",
    "    Encapsulation class of SSD network training.\n",
    "\n",
    "    Append an optimizer to the training network after that the construct\n",
    "    function can be called to create the backward graph.\n",
    "\n",
    "    Args:\n",
    "        network (Cell): The training network. Note that loss function should have been added.\n",
    "        optimizer (Optimizer): Optimizer for updating the weights.\n",
    "        sens (Number): The adjust parameter. Default: 1.0.\n",
    "        use_global_nrom(bool): Whether apply global norm before optimizer. Default: False\n",
    "    \"\"\"\n",
    "    def __init__(self, network, optimizer, sens=1.0, use_global_norm=False):\n",
    "        super(TrainingWrapper, self).__init__(auto_prefix=False)\n",
    "        self.network = network\n",
    "        self.network.set_grad()\n",
    "        self.weights = ms.ParameterTuple(network.trainable_params())\n",
    "        self.optimizer = optimizer\n",
    "        self.grad = ops.GradOperation(get_by_list=True, sens_param=True)\n",
    "        self.sens = sens\n",
    "        self.reducer_flag = False\n",
    "        self.grad_reducer = None\n",
    "        self.use_global_norm = use_global_norm\n",
    "        self.parallel_mode = ms.context.get_auto_parallel_context(\"parallel_mode\")    #获取自动并行的配置\n",
    "        if self.parallel_mode in [ParallelMode.DATA_PARALLEL, ParallelMode.HYBRID_PARALLEL]:\n",
    "            self.reducer_flag = True\n",
    "        if self.reducer_flag:\n",
    "            mean = ms.context.get_auto_parallel_context(\"gradients_mean\")\n",
    "            if auto_parallel_context().get_device_num_is_set():\n",
    "                degree = ms.context.get_auto_parallel_context(\"device_num\")\n",
    "            else:\n",
    "                degree = get_group_size()\n",
    "            self.grad_reducer = nn.DistributedGradReducer(optimizer.parameters, mean, degree)\n",
    "        self.hyper_map = ops.HyperMap()\n",
    "\n",
    "    def construct(self, *args):\n",
    "        weights = self.weights\n",
    "        loss = self.network(*args)\n",
    "        sens = ops.Fill()(ops.DType()(loss), ops.Shape()(loss), self.sens)\n",
    "        grads = self.grad(self.network, weights)(*args, sens)\n",
    "        if self.reducer_flag:\n",
    "            # apply grad reducer on grads\n",
    "            grads = self.grad_reducer(grads)\n",
    "        if self.use_global_norm:\n",
    "            grads = self.hyper_map(ops.partial(grad_scale, ops.scalar_to_array(self.sens)), grads)\n",
    "            grads = ops.clip_by_global_norm(grads)\n",
    "        self.optimizer(grads)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f121827",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start train SSD, the first epoch will be slower because of the graph compilation.\n",
      "epoch: 1 step: 500, loss is 1.1967511177062988\n",
      "epoch: 1 step: 1000, loss is 1.9645483493804932\n",
      "epoch: 1 step: 1500, loss is 3.3260927200317383\n",
      "epoch: 1 step: 2000, loss is 3.5189990997314453\n",
      "epoch: 1 step: 2500, loss is 1.53545343875885\n",
      "epoch: 1 step: 3000, loss is 2.613701820373535\n",
      "epoch: 1 step: 3500, loss is 1.257282018661499\n",
      "epoch: 1 step: 4000, loss is 1.415034294128418\n",
      "epoch: 1 step: 4500, loss is 2.755115509033203\n",
      "epoch: 1 step: 5000, loss is 2.4415366649627686\n",
      "epoch: 1 step: 5500, loss is 2.3683834075927734\n",
      "epoch: 1 step: 6000, loss is 4.593798637390137\n",
      "epoch: 1 step: 6500, loss is 2.34679913520813\n",
      "epoch: 1 step: 7000, loss is 3.6881065368652344\n",
      "epoch: 1 step: 7500, loss is 9.352529525756836\n",
      "epoch: 1 step: 8000, loss is 3.220026969909668\n",
      "epoch: 1 step: 8500, loss is 3.7141976356506348\n",
      "epoch: 1 step: 9000, loss is 2.93027663230896\n",
      "epoch: 1 step: 9500, loss is 1.8321635723114014\n",
      "epoch: 1 step: 10000, loss is 5.904363632202148\n",
      "epoch: 1 step: 10500, loss is 4.899038314819336\n",
      "epoch: 1 step: 11000, loss is 2.0997374057769775\n",
      "epoch: 1 step: 11500, loss is 12.342948913574219\n",
      "epoch time: 4539586.489 ms, per step time: 378.678 ms\n"
     ]
    }
   ],
   "source": [
    "from mindspore.train.callback import CheckpointConfig, ModelCheckpoint, LossMonitor, TimeMonitor\n",
    "from mindspore.train import Model\n",
    "import os\n",
    "\n",
    "#预训练权重\n",
    "output_path = './ckpoint'\n",
    "pre_trained = os.path.join(output_path, 'pretrain/ssd-40_2997.ckpt')\n",
    "\n",
    "# 训练参数设置\n",
    "loss_scale = 1.0\n",
    "save_checkpoint_epochs = 10\n",
    "pre_trained_epoch_size = 0\n",
    "epoch_size = 1\n",
    "warmup_epochs = 2\n",
    "lr_init = 0.001\n",
    "lr_end_rate = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.00015\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "ckpt_config = CheckpointConfig(save_checkpoint_steps=500)\n",
    "ckpt_save_dir = output_path +'/ckpt_{}/'.format(rank)\n",
    "ckpoint_cb = ModelCheckpoint(prefix=\"ssd\", directory=ckpt_save_dir, config=ckpt_config)\n",
    "\n",
    "if pre_trained:\n",
    "    param_dict = ms.load_checkpoint(pre_trained)\n",
    "    ms.load_param_into_net(net, param_dict, True)\n",
    "\n",
    "lr = Tensor(get_lr(global_step=pre_trained_epoch_size * dataset_size, lr_init=lr_init, lr_end=lr_end_rate * 0.05, lr_max=0.05, warmup_epochs=warmup_epochs, total_epochs=epoch_size, steps_per_epoch=dataset_size))\n",
    "\n",
    "opt = nn.Momentum(filter(lambda x: x.requires_grad, net.get_parameters()), lr, momentum, weight_decay, loss_scale)\n",
    "net = TrainingWrapper(net, opt, loss_scale)\n",
    "\n",
    "callback = [TimeMonitor(data_size=dataset_size), LossMonitor(per_print_times=500), ckpoint_cb]\n",
    "# 确定图模型是否下沉到芯片上\n",
    "device_target = ms.context.get_context('device_target')\n",
    "dataset_sink_mode = device_target in ['Ascend', 'GPU']\n",
    "\n",
    "model = Model(net)\n",
    "print(\"Start train SSD, the first epoch will be slower because of the graph compilation.\")\n",
    "model.train(epoch_size, dataset, callbacks=callback, dataset_sink_mode=dataset_sink_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc5ce4a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ModelArts云训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d4a1d0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "使用ModelArts云服务器，[训练代码下载地址](https://gitee.com/mindspore/models/tree/master/official/cv/resnet)\n",
    "\n",
    "+ 参考资料：\n",
    "\n",
    "  [映射配置](https://support. cloud.com/develop-modelarts/develop-modelarts-0008.html#develop-modelarts-0008)\n",
    "\n",
    "  [MindSpore文档](https://www.mindspore.cn/docs/zh-CN/r1.7/index.html)\n",
    "\n",
    "+ 服务器选择：\n",
    "\n",
    "  Ascend-Powered-Engine | mindspore_1.5.1-cann_5.0.2-py_3.7-euler_2.8.3-aarch64\n",
    "\n",
    "训练的结果如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc0a25e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`epoch: 1 step: 593, loss is 4.861618\n",
    "epoch time: 159056.884 ms, per step time: 268.224 ms\n",
    "epoch: 2 step: 593, loss is 3.3050907\n",
    "epoch time: 16968.953 ms, per step time: 28.615 ms\n",
    "epoch: 3 step: 593, loss is 3.3940845\n",
    "epoch time: 16966.594 ms, per step time: 28.611 ms\n",
    "epoch: 4 step: 593, loss is 2.9396534\n",
    "epoch time: 16965.572 ms, per step time: 28.610 ms\n",
    "epoch: 5 step: 593, loss is 3.2398167\n",
    "epoch time: 16976.679 ms, per step time: 28.628 ms\n",
    "epoch: 6 step: 593, loss is 3.7939153\n",
    "epoch time: 16962.239 ms, per step time: 28.604 ms\n",
    "epoch: 7 step: 593, loss is 3.2843313\n",
    "epoch time: 16956.846 ms, per step time: 28.595 ms\n",
    "epoch: 8 step: 593, loss is 2.7121086\n",
    "epoch time: 16969.032 ms, per step time: 28.616 ms\n",
    "epoch: 9 step: 593, loss is 2.425384\n",
    "epoch time: 17019.372 ms, per step time: 28.700 ms\n",
    "epoch: 10 step: 593, loss is 2.3338633\n",
    "epoch time: 17616.221 ms, per step time: 29.707 ms\n",
    "…… …… …… …… …… …… …… …… …… ……`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3708755",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 网络模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47fb25d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_nms(all_boxes, all_scores, thres, max_boxes):\n",
    "    \"\"\"Apply NMS to bboxes.\"\"\"\n",
    "    y1 = all_boxes[:, 0]\n",
    "    x1 = all_boxes[:, 1]\n",
    "    y2 = all_boxes[:, 2]\n",
    "    x2 = all_boxes[:, 3]\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\n",
    "    order = all_scores.argsort()[::-1]\n",
    "    keep = []\n",
    "\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "\n",
    "        if len(keep) >= max_boxes:\n",
    "            break\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "\n",
    "        inds = np.where(ovr <= thres)[0]\n",
    "\n",
    "        order = order[inds + 1]\n",
    "    return keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59e124a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools.coco import COCO\n",
    "import json\n",
    "\n",
    "class COCOMetrics:\n",
    "    \"\"\"Calculate mAP of predicted bboxes.\"\"\"\n",
    "\n",
    "    def __init__(self, anno_json, classes, num_classes, min_score, nms_threshold, max_boxes):\n",
    "        self.num_classes = num_classes\n",
    "        self.classes = classes\n",
    "        self.min_score = min_score\n",
    "        self.nms_threshold = nms_threshold\n",
    "        self.max_boxes = max_boxes\n",
    "\n",
    "        self.val_cls_dict = {i: cls for i, cls in enumerate(classes)}\n",
    "        self.coco_gt = COCO(anno_json)\n",
    "        cat_ids = self.coco_gt.loadCats(self.coco_gt.getCatIds())\n",
    "        self.class_dict = {cat['name']: cat['id'] for cat in cat_ids}\n",
    "\n",
    "        self.predictions = []\n",
    "        self.img_ids = []\n",
    "\n",
    "    def update(self, batch):\n",
    "        pred_boxes = batch['boxes']\n",
    "        box_scores = batch['box_scores']\n",
    "        img_id = batch['img_id']\n",
    "        h, w = batch['image_shape']\n",
    "\n",
    "        final_boxes = []\n",
    "        final_label = []\n",
    "        final_score = []\n",
    "        self.img_ids.append(img_id)\n",
    "\n",
    "        for c in range(1, self.num_classes):\n",
    "            class_box_scores = box_scores[:, c]\n",
    "            score_mask = class_box_scores > self.min_score\n",
    "            class_box_scores = class_box_scores[score_mask]\n",
    "            class_boxes = pred_boxes[score_mask] * [h, w, h, w]\n",
    "\n",
    "            if score_mask.any():\n",
    "                nms_index = apply_nms(class_boxes, class_box_scores, self.nms_threshold, self.max_boxes)\n",
    "                class_boxes = class_boxes[nms_index]\n",
    "                class_box_scores = class_box_scores[nms_index]\n",
    "\n",
    "                final_boxes += class_boxes.tolist()\n",
    "                final_score += class_box_scores.tolist()\n",
    "                final_label += [self.class_dict[self.val_cls_dict[c]]] * len(class_box_scores)\n",
    "\n",
    "        for loc, label, score in zip(final_boxes, final_label, final_score):\n",
    "            res = {}\n",
    "            res['image_id'] = img_id\n",
    "            res['bbox'] = [loc[1], loc[0], loc[3] - loc[1], loc[2] - loc[0]]\n",
    "            res['score'] = score\n",
    "            res['category_id'] = label\n",
    "            self.predictions.append(res)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        with open('predictions.json', 'w') as f:\n",
    "            json.dump(self.predictions, f)\n",
    "\n",
    "        coco_dt = self.coco_gt.loadRes('predictions.json')\n",
    "        E = COCOeval(self.coco_gt, coco_dt, iouType='bbox')\n",
    "        E.params.imgIds = self.img_ids\n",
    "        E.evaluate()\n",
    "        E.accumulate()\n",
    "        E.summarize()\n",
    "        return E.stats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "864e86c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 21\n",
    "max_boxes = 100\n",
    "nms_threshold = 0.6\n",
    "min_score = 0.1\n",
    "\n",
    "def apply_eval(eval_param_dict):\n",
    "    net = eval_param_dict[\"net\"]\n",
    "    net.set_train(False)\n",
    "    ds = eval_param_dict[\"dataset\"]\n",
    "    anno_json = eval_param_dict[\"anno_json\"]\n",
    "    coco_metrics = COCOMetrics(anno_json=anno_json,\n",
    "                               classes=classes,\n",
    "                               num_classes=num_classes,\n",
    "                               max_boxes=max_boxes,\n",
    "                               nms_threshold=nms_threshold,\n",
    "                               min_score=min_score)\n",
    "    for data in ds.create_dict_iterator(output_numpy=True, num_epochs=1):\n",
    "        img_id = data['img_id']\n",
    "        img_np = data['image']\n",
    "        image_shape = data['image_shape']\n",
    "\n",
    "        output = net(Tensor(img_np))\n",
    "\n",
    "        for batch_idx in range(img_np.shape[0]):\n",
    "            pred_batch = {\n",
    "                \"boxes\": output[0].asnumpy()[batch_idx],\n",
    "                \"box_scores\": output[1].asnumpy()[batch_idx],\n",
    "                \"img_id\": int(np.squeeze(img_id[batch_idx])),\n",
    "                \"image_shape\": image_shape[batch_idx]\n",
    "            }\n",
    "            coco_metrics.update(pred_batch)\n",
    "    eval_metrics = coco_metrics.get_metrics()\n",
    "    return eval_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ffc0acf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "\n",
    "class SsdInferWithDecoder(nn.Cell):\n",
    "    \"\"\"\n",
    "    SSD Infer wrapper to decode the bbox locations.\n",
    "\n",
    "    Args:\n",
    "        network (Cell): the origin ssd infer network without bbox decoder.\n",
    "        default_boxes (Tensor): the default_boxes from anchor generator\n",
    "        config (dict): ssd config\n",
    "    Returns:\n",
    "        Tensor, the locations for bbox after decoder representing (y0,x0,y1,x1)\n",
    "        Tensor, the prediction labels.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, network, default_boxes):\n",
    "        super(SsdInferWithDecoder, self).__init__()\n",
    "        self.network = network\n",
    "        self.default_boxes = default_boxes\n",
    "        self.prior_scaling_xy = prior_scaling[0]\n",
    "        self.prior_scaling_wh = prior_scaling[1]\n",
    "\n",
    "    def construct(self, x):\n",
    "        pred_loc, pred_label = self.network(x)\n",
    "\n",
    "        default_bbox_xy = self.default_boxes[..., :2]\n",
    "        default_bbox_wh = self.default_boxes[..., 2:]\n",
    "        pred_xy = pred_loc[..., :2] * self.prior_scaling_xy * default_bbox_wh + default_bbox_xy\n",
    "        pred_wh = ops.Exp()(pred_loc[..., 2:] * self.prior_scaling_wh) * default_bbox_wh\n",
    "\n",
    "        pred_xy_0 = pred_xy - pred_wh / 2.0\n",
    "        pred_xy_1 = pred_xy + pred_wh / 2.0\n",
    "        pred_xy = ops.Concat(-1)((pred_xy_0, pred_xy_1))\n",
    "        pred_xy = ops.Maximum()(pred_xy, 0)\n",
    "        pred_xy = ops.Minimum()(pred_xy, 1)\n",
    "        return pred_xy, pred_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2103718",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "your_best_ckpt = 'ckpt_0/ssd_2-10_10608.ckpt'\n",
    "output_path = './ckpoint'\n",
    "Best_ckpt = os.path.join(output_path, your_best_ckpt)\n",
    "\n",
    "def ssd_eval(dataset_path, ckpt_path, anno_json):\n",
    "    \"\"\"SSD evaluation.\"\"\"\n",
    "    batch_size = 1\n",
    "    ds = create_ssd_dataset(dataset_path, batch_size=batch_size,\n",
    "                            is_training=False, use_multiprocessing=False)\n",
    "    if model_name == \"ssd300\":\n",
    "        net = SSD300(ssd_mobilenet_v2(), is_training=False)\n",
    "    else:\n",
    "        raise ValueError(f'model: {model_name} is not supported')\n",
    "    net = SsdInferWithDecoder(net, Tensor(default_boxes))\n",
    "\n",
    "    print(\"Load Checkpoint!\")\n",
    "    param_dict = ms.load_checkpoint(ckpt_path)\n",
    "    net.init_parameters_data()\n",
    "    ms.load_param_into_net(net, param_dict)\n",
    "\n",
    "    net.set_train(False)\n",
    "    total = ds.get_dataset_size() * batch_size\n",
    "    print(\"\\n========================================\\n\")\n",
    "    print(\"total images num: \", total)\n",
    "    print(\"Processing, please wait a moment.\")\n",
    "    eval_param_dict = {\"net\": net, \"dataset\": ds, \"anno_json\": anno_json}\n",
    "    mAP = apply_eval(eval_param_dict)\n",
    "    print(\"\\n========================================\\n\")\n",
    "    print(f\"mAP: {mAP}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba583d53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start create dataset!\n",
      "./dataset/voc/VOC\n",
      "Start Eval!\n",
      "Load Checkpoint!\n",
      "\n",
      "========================================\n",
      "\n",
      "total images num:  5137\n",
      "Processing, please wait a moment.\n",
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=7.69s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=40.69s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=20.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.109\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.212\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.304\n",
      "\n",
      "========================================\n",
      "\n",
      "mAP: 0.009721333892793282\n"
     ]
    }
   ],
   "source": [
    "voc_root = data_path\n",
    "json_path = os.path.join(voc_root, voc_json)\n",
    "\n",
    "ms.context.set_context(mode=ms.GRAPH_MODE, device_target=device_target)\n",
    "\n",
    "mindrecord_file = create_mindrecord(\"voc\", \"ssd_eval.mindrecord\", False)\n",
    "\n",
    "print(\"Start Eval!\")\n",
    "ssd_eval(mindrecord_file, Best_ckpt, json_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "326px",
    "width": "378px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "205.225px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
