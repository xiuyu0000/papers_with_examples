{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 人体关键点检测之MSPN\n",
    "\n",
    "人体关键点检测（Human Keypoints Detection）又称人体姿态估计，是计算机视觉中一个比较基础的任务。现有的人体姿态识别模型依据处理阶段的不同大致上可以分为两类：Single-stage与Multi-stage，即模型为单阶段或多阶段；依据处理关键点顺序的不同也可分为两类：Top-Down与Bottom-Up，即先定位人体再检测关键点或先检测关键点再关联人体实例。人体姿态识别作为人体动作识别、行为分析、人机交互等的前置任务，吸引了无数公司业务的融入参与以及各大计算机视觉大赛的背景赛题。本文介绍的MSPN模型在MS COCO Competition 2018 Keypoints赛道上拿下了冠军，在COCO数据集上取得了优异的检测效果。\n",
    "\n",
    "## 模型简介\n",
    "\n",
    "Multi-Stage Pose Network（MSPN）是一种Multi-stage、Top-Down的人体姿态识别算法。MSPN采用Residual Block作为Backbone结构的搭建范式，使用Cross Stage Feature Aggregation将不同Stage网络之间的信息巧妙地融合起来，再辅以Coarse to Fine Supervision与细致的参数选取，提升了Multi-stage模型的检测精度。\n",
    "\n",
    "## 数据预处理\n",
    "\n",
    "在运行本案例之前，请先确保运行环境已经配置好合适版本的Python环境并安装了MindSpore Vision套件。\n",
    "\n",
    "### 数据下载\n",
    "\n",
    "本案例使用MS COCO（2014）数据集作为训练集以及验证集，请在[MS COCO官网](https://cocodataset.org/#download)下载对应的图片数据文件，MS COCO标注文件存放于./datasets目录下。\n",
    "\n",
    "将下载完的数据集以及标注文件解压，数据集图片文件可存放于运行环境所在设备上的任意路径下，这里假设存放于\"/data0/coco/coco2014\"目录下；将标注文件存放于与src文件夹同目录下，即“./annotation”。coco2014文件夹下包含了MS COCO数据集的训练以及验证图片文件夹；annotation文件夹下包含det_json以及gt_json两个文件夹，分别包含人体目标检测检测框的标注文件以及MS COCO训练集与验证集的标注文件。\n",
    "\n",
    "数据集图片如下所示：\n",
    "\n",
    "![MS COCO](./images/90891.jpg)\n",
    "\n",
    "### 数据加载\n",
    "\n",
    "通过数据集加载接口加载数据集，并执行相应的标准化操作，以Tensor的形式输出加载后的数据。"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from mindspore.dataset.vision.c_transforms import Normalize\n",
    "from mindspore.dataset.transforms.py_transforms import Compose\n",
    "import mindspore.dataset.vision.py_transforms as py_trans\n",
    "import mindspore.dataset as ds\n",
    "\n",
    "from src.process_datasets.coco import COCODataset\n",
    "\n",
    "\n",
    "# 构建数据读取器\n",
    "normalize = Normalize(mean=[0.406, 0.456, 0.485], std=[0.225, 0.224, 0.229])\n",
    "transform = Compose([normalize, py_trans.ToTensor()])\n",
    "dataset = COCODataset(data_dir=\"/data0/coco/coco2014\",\n",
    "                      gt_file_path=\"./annotation/gt_json/train_val_minus_minival_2014.json\",\n",
    "                      keypoint_num=17,\n",
    "                      flip_pairs=[[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16]],\n",
    "                      upper_body_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "                      lower_body_ids=[11, 12, 13, 14, 15, 16],\n",
    "                      input_shape=[256, 192],\n",
    "                      output_shape=[64, 48],\n",
    "                      stage='train'\n",
    "                      )\n",
    "dataloader = ds.GeneratorDataset(source=dataset,\n",
    "                                 column_names=[\"img\", \"valid\", \"labels\"],\n",
    "                                 shuffle=True,\n",
    "                                 num_parallel_workers=4)\n",
    "dataloader = dataloader.map(operations=transform, input_columns=[\"img\"]).batch(32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型构建\n",
    "\n",
    "MSPN总体结构如下图所示：\n",
    "\n",
    "![MSPN](./images/mspn.png)\n",
    "\n",
    "### 模型基础卷积块\n",
    "\n",
    "本部分对模型的基础卷积块进行构建，分为Conv-BN-ACTIVATION模块、Residual Block模块、输出图像Tensor预卷积模块。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import mindspore.nn as nn\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Cell):\n",
    "    \"\"\" Basic Convolutional Block for MSPN\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Input Tensor Channels\n",
    "        out_channels (int): Output Tensor Channels\n",
    "        kernel_size (int): Convolutional Kernel Size\n",
    "        stride (int): Convolutional Stride\n",
    "        padding (int): Convolutional Padding\n",
    "        use_bn (bool): Whether to Use Batch Normalization. Default: True.\n",
    "        use_relu (bool): Whether to Use ReLU. Default: True.\n",
    "\n",
    "    Inputs:\n",
    "        Tensor\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> conv_block = ConvBlock(3, 16, kernel_size=1, stride=1, padding=0, use_bn=True, use_relu=True)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: int,\n",
    "                 stride: int,\n",
    "                 padding: int,\n",
    "                 use_bn: bool = True,\n",
    "                 use_relu: bool = True\n",
    "                 ) -> None:\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, pad_mode='pad',\n",
    "                              padding=padding, has_bias=True)\n",
    "        self.use_bn = use_bn\n",
    "        self.use_relu = use_relu\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"\"Construct Func\"\"\"\n",
    "        x = self.conv(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn(x)\n",
    "        if self.use_relu:\n",
    "            x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Cell):\n",
    "    \"\"\" Residual Block for MSPN\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Input Tensor Channels\n",
    "        channels (int): Output Tensor Channels\n",
    "        stride (int): Convolutional Stride. Default: 1.\n",
    "        downsample (nn.Cell, optional): Downsample Module Implemented Under the Wrap of nn.Cell. Default: None.\n",
    "\n",
    "    Inputs:\n",
    "        Tensor\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> bottleneck = Bottleneck(3, 16, stride=1, downsample=None)\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 channels: int,\n",
    "                 stride: int = 1,\n",
    "                 downsample: Optional[nn.Cell] = None\n",
    "                 ) -> None:\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv_bn_relu1 = ConvBlock(in_channels, channels, kernel_size=1, stride=1, padding=0, use_bn=True,\n",
    "                                       use_relu=True)\n",
    "        self.conv_bn_relu2 = ConvBlock(channels, channels, kernel_size=3, stride=stride, padding=1, use_bn=True,\n",
    "                                       use_relu=True)\n",
    "        self.conv_bn_relu3 = ConvBlock(channels, channels * self.expansion, kernel_size=1, stride=1, padding=0,\n",
    "                                       use_bn=True, use_relu=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"Construct Func\"\"\"\n",
    "        conv_block_out = self.conv_bn_relu1(x)\n",
    "        conv_block_out = self.conv_bn_relu2(conv_block_out)\n",
    "        conv_block_out = self.conv_bn_relu3(conv_block_out)\n",
    "\n",
    "        if self.downsample:\n",
    "            x = self.downsample(x)\n",
    "\n",
    "        conv_block_out += x\n",
    "        conv_block_out = self.relu(conv_block_out)\n",
    "\n",
    "        return conv_block_out\n",
    "\n",
    "\n",
    "class ResNetTop(nn.Cell):\n",
    "    \"\"\" First Module of MSPN\n",
    "\n",
    "    Inputs:\n",
    "        Tensor\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> res_top = ResNetTop()\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        super(ResNetTop, self).__init__()\n",
    "        self.conv = ConvBlock(3, 64, kernel_size=7, stride=2, padding=3, use_bn=True, use_relu=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, pad_mode='same')\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"Construct Func\"\"\"\n",
    "        out = self.conv(x)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 下采样模块\n",
    "\n",
    "本部分对模型的下采样模块进行实现，采用上述实现的基础卷积块与残差块对输入图像进行卷积，在减少Tensor尺寸的同时增大通道数，提取高层语义信息，同时输出用于上采样模块聚合信息的Skip Connection信息以及用于Cross Stage Feature Aggregation的信息。\n",
    "\n",
    "Cross Stage Feature Aggregation的细节结构如下图所示：\n",
    "\n",
    "![Cross Stage Feature Aggregation](./images/csfa.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mindspore\n",
    "from mindspore.common.initializer import initializer, HeNormal\n",
    "\n",
    "\n",
    "class ResNetDownsampleModule(nn.Cell):\n",
    "    \"\"\" Residual Downsample Module for MSPN\n",
    "\n",
    "    Args:\n",
    "        block (nn.Cell): Residual Downsample Module Implemented Under the Wrap of nn.Cell\n",
    "        layer_num_list (list): Num of Stacking Residual Blocks\n",
    "        use_skip (bool): Whether to Use Cross Stage Feature Aggregation. Default: False.\n",
    "        zero_init_bn (bool): Whether to Use zero initialization On Weight of Batch Normalization. Default: False.\n",
    "\n",
    "    Inputs:\n",
    "        Tensor, skip_tensor of previous MSPN Stage\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> downsample = ResNetDownsampleModule(Bottleneck, layer_num_list=[3, 4, 6, 3])\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 block: nn.Cell,\n",
    "                 layer_num_list: list,\n",
    "                 use_skip: bool = False,\n",
    "                 zero_init_bn: bool = False\n",
    "                 ) -> None:\n",
    "        super(ResNetDownsampleModule, self).__init__()\n",
    "        self.use_skip = use_skip\n",
    "        self.in_channels = 64\n",
    "        self.layer1 = self._make_layer(block, 64, layer_num_list[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layer_num_list[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layer_num_list[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layer_num_list[3], stride=2)\n",
    "\n",
    "        for _, m in self.cells_and_names():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight = initializer(HeNormal(mode='fan_out', nonlinearity='relu'), m.weight.shape, mindspore.float32)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.gamma = initializer(1, m.gamma.shape, mindspore.float32)\n",
    "                m.beta = initializer(0, m.beta.shape, mindspore.float32)\n",
    "\n",
    "        if zero_init_bn:\n",
    "            for _, m in self.cells_and_names():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    m.bn3.weight = initializer(0, m.bn3.weight.shape, mindspore.float32)\n",
    "\n",
    "    def _make_layer(self, block, channels, num_blocks, stride=1):\n",
    "        \"\"\"Stacking Residual Blocks\"\"\"\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != channels * block.expansion:\n",
    "            downsample = ConvBlock(self.in_channels, channels * block.expansion, kernel_size=1, stride=stride,\n",
    "                                   padding=0, use_bn=True, use_relu=False)\n",
    "\n",
    "        layers = list()\n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "        self.in_channels = channels * block.expansion\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(self.in_channels, channels))\n",
    "\n",
    "        return nn.SequentialCell(*layers)\n",
    "\n",
    "    def construct(self, x, skip_tensor_1, skip_tensor_2):\n",
    "        \"\"\"Construct Func\"\"\"\n",
    "        x1 = self.layer1(x)\n",
    "        if self.use_skip:\n",
    "            x1 = x1 + skip_tensor_1[0] + skip_tensor_2[0]\n",
    "        x2 = self.layer2(x1)\n",
    "        if self.use_skip:\n",
    "            x2 = x2 + skip_tensor_1[1] + skip_tensor_2[1]\n",
    "        x3 = self.layer3(x2)\n",
    "        if self.use_skip:\n",
    "            x3 = x3 + skip_tensor_1[2] + skip_tensor_2[2]\n",
    "        x4 = self.layer4(x3)\n",
    "        if self.use_skip:\n",
    "            x4 = x4 + skip_tensor_1[3] + skip_tensor_2[3]\n",
    "\n",
    "        return x4, x3, x2, x1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 上采样模块\n",
    "\n",
    "本部分对模型的上采样模块进行实现，融合了上采样操作的实现以及聚合从下采样模块输出的特征信息以及上一个上采样单元的输出信息，并输出用于进行Coarse to Fine Supervison的监督信息以及用于下一个Stage的Cross Stage Feature Aggragation的跨阶段特征信息。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class UpsampleUnit(nn.Cell):\n",
    "    \"\"\" Upsample Unit for MSPN\n",
    "\n",
    "    Args:\n",
    "        ind (int): The order index of UpsampleUnit in UpsampleModule\n",
    "        in_channels (int): Input Tensor Channels\n",
    "        upsample_size (tuple): Upsample Tensor Shape\n",
    "        output_channel_num (int): Output Tensor Channels\n",
    "        output_shape (tuple): Output Tensor Shape\n",
    "        channel_num (int): Interim Tensor Channels. Default: 256.\n",
    "        generate_skip (bool): Whether to generate skip connection output tensor. Default: False.\n",
    "        generate_cross_conv (bool): Whether to apply Convolution for the output Tensor to further feed into next stage \\\n",
    "        Module. Default: False.\n",
    "\n",
    "    Inputs:\n",
    "        Tensor, Upsample Tensor from Previous Layer.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> upsample_unit = UpsampleUnit(0, 3, (128, 128), 16, (256, 256), channel_num=256, generate_skip=False)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 ind: int,\n",
    "                 in_channels: int,\n",
    "                 upsample_size: tuple,\n",
    "                 output_channel_num: int,\n",
    "                 output_shape: tuple,\n",
    "                 channel_num: int = 256,\n",
    "                 generate_skip: bool = False,\n",
    "                 generate_cross_conv: bool = False\n",
    "                 ) -> None:\n",
    "        super(UpsampleUnit, self).__init__()\n",
    "        self.output_shape = output_shape\n",
    "        self.resize_bilinear = nn.ResizeBilinear()\n",
    "        self.u_skip = ConvBlock(in_channels, channel_num, kernel_size=1, stride=1, padding=0, use_bn=True,\n",
    "                                use_relu=False)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.ind = ind\n",
    "        if self.ind > 0:\n",
    "            self.upsample_size = upsample_size\n",
    "            self.up_conv = ConvBlock(channel_num, channel_num, kernel_size=1, stride=1, padding=0, use_bn=True,\n",
    "                                     use_relu=False)\n",
    "\n",
    "        self.generate_skip = generate_skip\n",
    "        if self.generate_skip:\n",
    "            self.skip1 = ConvBlock(in_channels, in_channels, kernel_size=1, stride=1, padding=0, use_bn=True,\n",
    "                                   use_relu=True)\n",
    "            self.skip2 = ConvBlock(channel_num, in_channels, kernel_size=1, stride=1, padding=0, use_bn=True,\n",
    "                                   use_relu=True)\n",
    "\n",
    "        self.generate_cross_conv = generate_cross_conv\n",
    "        if self.ind == 3 and self.generate_cross_conv:\n",
    "            self.cross_conv = ConvBlock(channel_num, 64, kernel_size=1, stride=1, padding=0, use_bn=True,\n",
    "                                        use_relu=True)\n",
    "\n",
    "        self.res_conv1 = ConvBlock(channel_num, channel_num, kernel_size=1, stride=1, padding=0, use_bn=True,\n",
    "                                   use_relu=True)\n",
    "        self.res_conv2 = ConvBlock(channel_num, output_channel_num, kernel_size=3, stride=1, padding=1, use_bn=True,\n",
    "                                   use_relu=False)\n",
    "\n",
    "    def construct(self, x, up_x):\n",
    "        \"\"\"Construct Func\"\"\"\n",
    "        out = self.u_skip(x)\n",
    "\n",
    "        if self.ind > 0:\n",
    "            up_x = self.resize_bilinear(up_x, size=self.upsample_size, align_corners=True)\n",
    "            up_x = self.up_conv(up_x)\n",
    "            out += up_x\n",
    "        out = self.relu(out)\n",
    "\n",
    "        res = self.res_conv1(out)\n",
    "        res = self.res_conv2(res)\n",
    "        res = self.resize_bilinear(res, size=self.output_shape, align_corners=True)\n",
    "\n",
    "        skip_tensor_1 = None\n",
    "        skip_tensor_2 = None\n",
    "        if self.generate_skip:\n",
    "            skip_tensor_1 = self.skip1(x)\n",
    "            skip_tensor_2 = self.skip2(out)\n",
    "\n",
    "        cross_conv = None\n",
    "        if self.ind == 3 and self.generate_cross_conv:\n",
    "            cross_conv = self.cross_conv(out)\n",
    "\n",
    "        return out, res, skip_tensor_1, skip_tensor_2, cross_conv\n",
    "\n",
    "\n",
    "class UpsampleModule(nn.Cell):\n",
    "    \"\"\" Upsample Module for MSPN\n",
    "\n",
    "    Args:\n",
    "        output_channel_num (int): Output Tensor Channels\n",
    "        output_shape (tuple): Output Tensor Shape\n",
    "        channel_num (int): Interim Tensor Channels. Default: 256.\n",
    "        generate_skip (bool): Whether to generate skip connection output tensor. Default: False.\n",
    "        generate_cross_conv (bool): Whether to apply Convolution for the output Tensor to further feed into next stage \\\n",
    "        Module. Default: False.\n",
    "\n",
    "    Inputs:\n",
    "        Tensors from Output of Every Downsample Layer.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> upsample = UpsampleModule(64, (256, 256), channel_num=256, generate_skip=False, generate_cross_conv=False)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 output_channel_num: int,\n",
    "                 output_shape: tuple,\n",
    "                 channel_num: int = 256,\n",
    "                 generate_skip: bool = False,\n",
    "                 generate_cross_conv: bool = False\n",
    "                 ) -> None:\n",
    "        super(UpsampleModule, self).__init__()\n",
    "        self.in_channels = [2048, 1024, 512, 256]\n",
    "        h, w = output_shape\n",
    "        self.upsample_sizes = [(h // 8, w // 8), (h // 4, w // 4), (h // 2, w // 2), (h, w)]\n",
    "        self.generate_skip = generate_skip\n",
    "        self.generate_cross_conv = generate_cross_conv\n",
    "\n",
    "        self.up1 = UpsampleUnit(0, self.in_channels[0], self.upsample_sizes[0], output_channel_num=output_channel_num,\n",
    "                                output_shape=output_shape, channel_num=channel_num, generate_skip=self.generate_skip,\n",
    "                                generate_cross_conv=self.generate_cross_conv)\n",
    "        self.up2 = UpsampleUnit(1, self.in_channels[1], self.upsample_sizes[1], output_channel_num=output_channel_num,\n",
    "                                output_shape=output_shape, channel_num=channel_num, generate_skip=self.generate_skip,\n",
    "                                generate_cross_conv=self.generate_cross_conv)\n",
    "        self.up3 = UpsampleUnit(2, self.in_channels[2], self.upsample_sizes[2], output_channel_num=output_channel_num,\n",
    "                                output_shape=output_shape, channel_num=channel_num, generate_skip=self.generate_skip,\n",
    "                                generate_cross_conv=self.generate_cross_conv)\n",
    "        self.up4 = UpsampleUnit(3, self.in_channels[3], self.upsample_sizes[3], output_channel_num=output_channel_num,\n",
    "                                output_shape=output_shape, channel_num=channel_num, generate_skip=self.generate_skip,\n",
    "                                generate_cross_conv=self.generate_cross_conv)\n",
    "\n",
    "    def construct(self, x4, x3, x2, x1):\n",
    "        \"\"\"Construct Func\"\"\"\n",
    "        out1, res1, skip1_1, skip2_1, _ = self.up1(x4, None)\n",
    "        out2, res2, skip1_2, skip2_2, _ = self.up2(x3, out1)\n",
    "        out3, res3, skip1_3, skip2_3, _ = self.up3(x2, out2)\n",
    "        _, res4, skip1_4, skip2_4, cross_conv = self.up4(x1, out3)\n",
    "\n",
    "        # 'res' starts from small size\n",
    "        res = [res1, res2, res3, res4]\n",
    "        skip_tensor_1 = [skip1_4, skip1_3, skip1_2, skip1_1]\n",
    "        skip_tensor_2 = [skip2_4, skip2_3, skip2_2, skip2_1]\n",
    "\n",
    "        return res, skip_tensor_1, skip_tensor_2, cross_conv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 单阶段模型构建\n",
    "\n",
    "在构建出上述基本模块后，我们可以构建出MSPN中的单阶段网络结构模块。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SingleStageModule(nn.Cell):\n",
    "    \"\"\" Single Stage Module for MSPN\n",
    "\n",
    "    Args:\n",
    "        output_channel_num (int): Output Tensor Channels\n",
    "        output_shape (tuple): Output Tensor Shape\n",
    "        use_skip (bool): Whether to Use Cross Stage Feature Aggregation. Default: False.\n",
    "        generate_skip (bool): Whether to generate skip connection output tensor. Default: False.\n",
    "        generate_cross_conv (bool): Whether to apply Convolution for the output Tensor to further feed into next stage \\\n",
    "        Module. Default: False.\n",
    "        channel_num (int): Interim Tensor Channels. Default: 256.\n",
    "        zero_init_bn (bool): Whether to Use zero initialization On Weight of Batch Normalization. Default: False.\n",
    "\n",
    "    Inputs:\n",
    "        Tensor, skip_tensor of previous MSPN Stage\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> single_stage = SingleStageModule(128, (256, 256), use_skip=False, generate_skip=False)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 output_channel_num: int,\n",
    "                 output_shape: tuple,\n",
    "                 use_skip: bool = False,\n",
    "                 generate_skip: bool = False,\n",
    "                 generate_cross_conv: bool = False,\n",
    "                 channel_num: int = 256,\n",
    "                 zero_init_bn: bool = False\n",
    "                 ) -> None:\n",
    "        super(SingleStageModule, self).__init__()\n",
    "        self.use_skip = use_skip\n",
    "        self.generate_skip = generate_skip\n",
    "        self.generate_cross_conv = generate_cross_conv\n",
    "        self.channel_num = channel_num\n",
    "        self.zero_init_bn = zero_init_bn\n",
    "        self.layers = [3, 4, 6, 3]\n",
    "        self.downsample = ResNetDownsampleModule(Bottleneck, self.layers, self.use_skip, self.zero_init_bn)\n",
    "        self.upsample = UpsampleModule(output_channel_num, output_shape, self.channel_num, self.generate_skip,\n",
    "                                       self.generate_cross_conv)\n",
    "\n",
    "    def construct(self, x, skip_tensor_1, skip_tensor_2):\n",
    "        \"\"\"Construct Func\"\"\"\n",
    "        x4, x3, x2, x1 = self.downsample(x, skip_tensor_1, skip_tensor_2)\n",
    "        res, skip_tensor_1, skip_tensor_2, cross_conv = self.upsample(x4, x3, x2, x1)\n",
    "\n",
    "        return res, skip_tensor_1, skip_tensor_2, cross_conv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 损失函数\n",
    "\n",
    "MSPN的损失函数计算采取L2 Loss，即Mean Square Error（MSE）作为基础损失函数：\n",
    "\n",
    "$$\n",
    "MSE = \\frac{\\sum\\limits_{i=1}^{n}(y_i-y_i^p)^2}{n}\n",
    "$$\n",
    "\n",
    "其中，$n$为样本数，$y_i$为样本真实值，$y_i^p$为模型对于该样本的预测值\n",
    "\n",
    "在这之上，作者额外使用了两种辅助策略来计算损失，以便使模型达到更好的效果：\n",
    "\n",
    "- Coarse to Fine Supervision（CTF）：作者对不同Stage的输出采取不同尺寸高斯卷积核处理后的Ground Truth进行损失计算。越靠前的Stage使用的卷积核尺寸越大，Ground Truth越“模糊”；越靠后的Stage使用的卷积核尺寸越小，Ground Truth越“精细”。这种Ground Truth的变化趋势正好对应着模型学习的阶段过程，示意图如下：\n",
    "\n",
    "![Coarse to Fine Supervison](./images/ctf.png)\n",
    "\n",
    "- Online Hard Keypoint Minning（OHKM）：作者采用了困难样本挖掘的思想对损失函数进行改进，即在每一个Stage只取损失最高的K个关键点作为损失计算，这种方式有利于网络加强对难学习样本的拟合性能，从而提高模型整体性能。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class StageLoss(nn.Cell):\n",
    "    \"\"\" Stage Loss for Every Stage of MSPN\n",
    "\n",
    "    Args:\n",
    "        has_ohkm (bool): Whether to use Online Hard Key points Mining (OHKM). Default: False.\n",
    "        topk (int): OHKM Top-k Largest Loss Hyper-parameter. Default: 8.\n",
    "        vis_thresh_wo_ohkm (int): Joints Visible Thresh when has_ohkm sets to False. Default: 1.\n",
    "        vis_thresh_w_ohkm (int): Joints Visible Thresh when has_ohkm sets to True. Default: 0.\n",
    "\n",
    "    Inputs:\n",
    "        MSPN Output Tensor, Keypoints Visible Tensor, Keypoints Ground Truth Tensor\n",
    "\n",
    "    Returns:\n",
    "        Tensor of Loss.\n",
    "\n",
    "    Examples:\n",
    "        >>> stage_loss = StageLoss(has_ohkm=True, topk=8)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 has_ohkm: bool = False,\n",
    "                 topk: int = 8,\n",
    "                 vis_thresh_wo_ohkm: int = 1,\n",
    "                 vis_thresh_w_ohkm: int = 0\n",
    "                 ) -> None:\n",
    "        super(StageLoss, self).__init__()\n",
    "        self.has_ohkm = has_ohkm\n",
    "        self.topk = topk\n",
    "        self.t1 = vis_thresh_wo_ohkm\n",
    "        self.t2 = vis_thresh_w_ohkm\n",
    "        method = 'none' if self.has_ohkm else 'mean'\n",
    "        self.calculate = nn.MSELoss(reduction=method)\n",
    "\n",
    "    def construct(self, output, valid, label):\n",
    "        \"\"\"Construct Func\"\"\"\n",
    "        greater = mindspore.ops.Greater()\n",
    "        topk = mindspore.ops.TopK(sorted=False)\n",
    "        batch_size = output.shape[0]\n",
    "        keypoint_num = output.shape[1]\n",
    "        loss = 0\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            pred = output[i].reshape(keypoint_num, -1)\n",
    "            gt = label[i].reshape(keypoint_num, -1)\n",
    "            if not self.has_ohkm:\n",
    "                weight = greater(valid[i], self.t1).astype(mindspore.float32)\n",
    "                gt = gt * weight\n",
    "\n",
    "            tmp_loss = self.calculate(pred, gt)\n",
    "            if self.has_ohkm:\n",
    "                tmp_loss = tmp_loss.mean(axis=1)\n",
    "                weight = greater(valid[i].squeeze(), self.t2).astype(mindspore.float32)\n",
    "                tmp_loss = tmp_loss * weight\n",
    "                topk_val, _ = topk(tmp_loss, self.topk)\n",
    "                sample_loss = topk_val.mean(axis=0)\n",
    "            else:\n",
    "                sample_loss = tmp_loss\n",
    "\n",
    "            loss = loss + sample_loss\n",
    "\n",
    "        return loss / batch_size\n",
    "\n",
    "\n",
    "class JointsL2Loss(nn.Cell):\n",
    "    \"\"\" JointsL2 Loss for MSPN\n",
    "\n",
    "    Args:\n",
    "        stage_num (int): MSPN Stage Num\n",
    "        ctf (bool): Whether to enable Coarse-to-Fine Supervision. Default: True.\n",
    "        has_ohkm (bool): Whether to use Online Hard Key points Mining (OHKM). Default: False.\n",
    "        topk (int): OHKM Top-k Largest Loss Hyper-parameter. Default: 8.\n",
    "\n",
    "    Inputs:\n",
    "        MSPN Output Tensor, Keypoints Visible Tensor, Keypoints Ground Truth Tensor\n",
    "\n",
    "    Returns:\n",
    "        Tensor of Loss.\n",
    "\n",
    "    Examples:\n",
    "        >>> joints_loss = JointsL2Loss(stage_num=0, ctf=True, has_ohkm=True, topk=8)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 stage_num: int,\n",
    "                 ctf: bool = True,\n",
    "                 has_ohkm: bool = False,\n",
    "                 topk: int = 8\n",
    "                 ) -> None:\n",
    "        super(JointsL2Loss, self).__init__()\n",
    "        self.stage_num = stage_num\n",
    "        self.ctf = ctf\n",
    "        self.ohkm = has_ohkm\n",
    "        self.topk = topk\n",
    "        self.loss = StageLoss()\n",
    "        self.loss_ohkm = StageLoss(has_ohkm=self.ohkm, topk=self.topk)\n",
    "\n",
    "    def construct(self, outputs, valids, labels):\n",
    "        \"\"\"Construct Func\"\"\"\n",
    "        loss = 0\n",
    "        for i in range(self.stage_num):\n",
    "            for j in range(4):\n",
    "                ind = j\n",
    "                if i == self.stage_num - 1 and self.ctf:\n",
    "                    ind += 1\n",
    "                tmp_labels = labels[:, ind, :, :, :]\n",
    "\n",
    "                if j == 3 and self.ohkm:\n",
    "                    tmp_loss = self.loss_ohkm(outputs[i][j], valids, tmp_labels)\n",
    "                else:\n",
    "                    tmp_loss = self.loss(outputs[i][j], valids, tmp_labels)\n",
    "\n",
    "                if j < 3:\n",
    "                    tmp_loss = tmp_loss / 4\n",
    "\n",
    "                loss += tmp_loss\n",
    "\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MSPN模型实现\n",
    "\n",
    "在前述介绍中，我们从最基础的卷积块开始，依次实现了下采样、上采样、MSPN单阶段网络结构以及损失函数。接下来我们综合上述实现的子模块对MSPN模型进行实现。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MSPN(nn.Cell):\n",
    "    \"\"\" MSPN\n",
    "\n",
    "    Args:\n",
    "        total_stage_num (int): MSPN Stage Num\n",
    "        output_channel_num (int): Output Tensor Channels\n",
    "        output_shape (tuple): Output Tensor Shape\n",
    "        upsample_channel_num (int): Upsample Tensor Channels\n",
    "        online_hard_key_mining (bool): Whether to use Online Hard Key points Mining (OHKM). Default: True.\n",
    "        topk_keys (int): OHKM Top-k Largest Loss Hyper-parameter. Default: 8.\n",
    "        coarse_to_fine (bool): Whether to enable Coarse-to-Fine Supervision. Default: True.\n",
    "\n",
    "    Inputs:\n",
    "        Image Tensor, Keypoints Visible Tensor, Keypoints Ground Truth.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> mspn = MSPN(2, 17, (64, 48), 256, ohkm=True, topk=8, ctf=True)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 total_stage_num: int,\n",
    "                 output_channel_num: int,\n",
    "                 output_shape: tuple,\n",
    "                 upsample_channel_num: int,\n",
    "                 online_hard_key_mining: bool = True,\n",
    "                 topk_keys: int = 8,\n",
    "                 coarse_to_fine: bool = True,\n",
    "                 ) -> None:\n",
    "        super(MSPN, self).__init__()\n",
    "        self.top = ResNetTop()\n",
    "        self.total_stage_num = total_stage_num\n",
    "        self.output_channel_num = output_channel_num\n",
    "        self.output_shape = output_shape\n",
    "        self.upsample_channel_num = upsample_channel_num\n",
    "        self.online_hard_key_mining = online_hard_key_mining\n",
    "        self.topk_keys = topk_keys\n",
    "        self.coarse_to_fine = coarse_to_fine\n",
    "        self.mspn_modules = list()\n",
    "        for i in range(self.total_stage_num):\n",
    "            if i == 0:\n",
    "                use_skip = False\n",
    "            else:\n",
    "                use_skip = True\n",
    "            if i != self.total_stage_num - 1:\n",
    "                generate_skip = True\n",
    "                generate_cross_conv = True\n",
    "            else:\n",
    "                generate_skip = False\n",
    "                generate_cross_conv = False\n",
    "            self.mspn_modules.append(\n",
    "                SingleStageModule(\n",
    "                    self.output_channel_num, self.output_shape,\n",
    "                    use_skip=use_skip, generate_skip=generate_skip,\n",
    "                    generate_cross_conv=generate_cross_conv,\n",
    "                    channel_num=self.upsample_channel_num,\n",
    "                )\n",
    "            )\n",
    "            setattr(self, 'stage%d' % i, self.mspn_modules[i])\n",
    "        self.loss = JointsL2Loss(stage_num=self.total_stage_num, ctf=self.coarse_to_fine,\n",
    "                                 has_ohkm=self.online_hard_key_mining, topk=self.topk_keys)\n",
    "\n",
    "    def construct(self, imgs, valids=None, labels=None):\n",
    "        \"\"\"Construct Func\"\"\"\n",
    "        x = self.top(imgs)\n",
    "        skip_tensor_1 = None\n",
    "        skip_tensor_2 = None\n",
    "        outputs = list()\n",
    "        for i in range(self.total_stage_num):\n",
    "            res, skip_tensor_1, skip_tensor_2, x = self.mspn_modules[i](x, skip_tensor_1, skip_tensor_2)\n",
    "            outputs.append(res)\n",
    "\n",
    "        if valids is None and labels is None:\n",
    "            return outputs[-1][-1]\n",
    "\n",
    "        return self.loss(outputs, valids, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型训练\n",
    "\n",
    "在完成上述模块搭建工作后，我们可以对MSPN模型进行训练。为了简化训练过程，我们仅对模型训练1个epoch，且MSPN的阶段数设为2，以便于适应不同性能的计算设备。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mindspore import context\n",
    "from mindspore.train.callback import LossMonitor\n",
    "\n",
    "\n",
    "context.set_context(mode=context.PYNATIVE_MODE, device_id=0, device_target=\"GPU\")\n",
    "\n",
    "step_size = dataloader.get_dataset_size()\n",
    "EPOCH = 1\n",
    "\n",
    "# 实例化MSPN模型\n",
    "net = MSPN(total_stage_num=2,\n",
    "           output_channel_num=17,\n",
    "           output_shape=[64, 48],\n",
    "           upsample_channel_num=256,\n",
    "           online_hard_key_mining=True,\n",
    "           topk_keys=8,\n",
    "           coarse_to_fine=True)\n",
    "\n",
    "# 设定学习率调整器\n",
    "lr = nn.cosine_decay_lr(min_lr=0.0,\n",
    "                        max_lr=5e-4,\n",
    "                        total_step=EPOCH * step_size,\n",
    "                        step_per_epoch=step_size,\n",
    "                        decay_epoch=EPOCH)\n",
    "\n",
    "# 设定优化器\n",
    "optimizer = nn.Adam(net.trainable_params(), learning_rate=lr)\n",
    "\n",
    "# 加载预训练权重\n",
    "mindspore.load_param_into_net(net, mindspore.load_checkpoint(\"mspn.ckpt\"))\n",
    "\n",
    "# 初始化模型\n",
    "model = mindspore.Model(net, optimizer=optimizer)\n",
    "\n",
    "# 开始训练\n",
    "model.train(epoch=EPOCH, train_dataset=dataloader, callbacks=LossMonitor())\n",
    "\n",
    "# Save Model ckpt\n",
    "mindspore.save_checkpoint(net, \"./mspn_new.ckpt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型评估\n",
    "\n",
    "在训练完成后，我们对训练收敛的模型在MS COCO验证集上进行评估。\n",
    "\n",
    "为了更全面地衡量MSPN模型的性能，我们沿用MSPN原文的AP、AR指标对模型进行评估。类似于目标检测中使用IoU对预测结果与Ground Truth进行相似度度量，从而根据IoU设定阈值计算出各种AP、AR值。类似地，在姿态识别领域，MS COCO官方对关键点也给出了类似于IoU的定义：\n",
    "\n",
    "$$\n",
    "O K S=\\frac{\\sum_{i} \\exp \\left[\\frac{-d_{i}^{2}}{2 s^{2} k_{i}^{2}} \\delta\\left(v_{i}>0\\right)\\right]}{\\sum_{i} \\delta\\left(v_{i}>0\\right)}\n",
    "$$\n",
    "\n",
    "OKS全称Object Keypoint Similarity。其中，$i$为关键点个数；$d_i^2$表示关键点$i$预测值与Ground Truth之间的欧氏距离；$s$表示Ground Truth行人的尺度因子，其值为行人检测框面积的平方根，这里的$s$与关键点无关；$k_i$表示第$i$个关键点的归一化因子的2倍，这个因子是通过对所有的样本集中的Ground Truth关键点由人工标注与真实值存在的标准差，越大表示此类型的关键点越难标注，而$k_i$越大，对应的OKS的值就会越大；$v_i$表示第$i$个关键点的可见性，$0$表示关键点未标记，$1$表示无遮挡并且已经标记，$2$表示有遮挡但是已经标记。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from mindspore import context\n",
    "from src.utils.mspn_utils import compute_on_dataset, evaluate\n",
    "\n",
    "\n",
    "FLIP_PAIRS = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16]]\n",
    "\n",
    "context.set_context(mode=context.PYNATIVE_MODE, device_id=0, device_target=\"GPU\")\n",
    "\n",
    "normalize = Normalize(mean=[0.406, 0.456, 0.485], std=[0.225, 0.224, 0.229])\n",
    "transform = Compose([normalize, py_trans.ToTensor()])\n",
    "dataset = COCODataset(data_dir=\"/data0/coco/coco2014\",\n",
    "                      det_file_path=\"./annotation/det_json/minival_2014_det.json\",\n",
    "                      gt_file_path=\"./annotation/gt_json/minival_2014.json\",\n",
    "                      keypoint_num=17,\n",
    "                      flip_pairs=FLIP_PAIRS,\n",
    "                      upper_body_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "                      lower_body_ids=[11, 12, 13, 14, 15, 16],\n",
    "                      input_shape=[256, 192],\n",
    "                      output_shape=[64, 48],\n",
    "                      stage='val'\n",
    "                      )\n",
    "dataloader = ds.GeneratorDataset(source=dataset,\n",
    "                                 column_names=[\"img\", \"score\", \"center\", \"scale\", \"img_id\"],\n",
    "                                 shuffle=False,\n",
    "                                 num_parallel_workers=4)\n",
    "dataloader = dataloader.map(operations=transform, input_columns=[\"img\"]).batch(32)\n",
    "\n",
    "# 实例化MSPN模型\n",
    "net = MSPN(total_stage_num=2,\n",
    "           output_channel_num=17,\n",
    "           output_shape=[64, 48],\n",
    "           upsample_channel_num=256,\n",
    "           online_hard_key_mining=True,\n",
    "           topk_keys=8,\n",
    "           coarse_to_fine=True)\n",
    "\n",
    "# 加载预训练权重\n",
    "mindspore.load_param_into_net(net, mindspore.load_checkpoint(\"mspn_new.ckpt\"))\n",
    "\n",
    "# 初始化模型\n",
    "model = mindspore.Model(net)\n",
    "\n",
    "# 开始评估\n",
    "results = compute_on_dataset(model=model,\n",
    "                             dataloader=dataloader,\n",
    "                             flip_pairs=FLIP_PAIRS,\n",
    "                             keypoint_num=17,\n",
    "                             input_shape=[256, 192],\n",
    "                             output_shape=[64, 48])\n",
    "results.sort(key=lambda res: (res['image_id'], res['score']), reverse=True)\n",
    "with open('./results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "evaluate(val_gt_path=\"./annotation/gt_json/minival_2014.json\",\n",
    "         pred_path='./results.json')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型推理\n",
    "\n",
    "由于MSPN是Top-Down模型，即需要先检测出人体检测框再对各个检测框进行关键点检测，所以MSPN模型推理需要额外提供待推理图片的人体检测框标注JSON文件，单个检测框的标注格式如下所示："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "{\n",
    "    \"category_id\": 1,\n",
    "    \"image_id\": 398905,\n",
    "    \"bbox\": [\n",
    "        216.39,\n",
    "        32.29,\n",
    "        295.74,\n",
    "        333.67\n",
    "    ],\n",
    "    \"score\": 0.9951\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- category_id：在MSPN中恒为1，与MS COCO Detection的行人标注标签一致。\n",
    "- image_id：待推理图像的文件名ID\n",
    "- bbox：检测框的尺寸信息XYHW，分别表示左上角点的横坐标与纵坐标、检测框的长与宽\n",
    "- score：检测框的置信度\n",
    "\n",
    "将待推理的图像修改名称为非0开头的纯数字文件名，并放置于./infer_img文件夹下；将待推理图像的检测框信息JSON文件放置于./annotation/det_json文件夹下。可同时将多张图片存放于./infer_img文件下一次性全部进行推理，但需保证标注JSON文件中的image_id必须和./infer_img文件夹下的待推理图片名称相对应。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mindspore import context\n",
    "from src.utils.mspn_utils import compute_on_dataset, visualize\n",
    "\n",
    "\n",
    "FLIP_PAIRS = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16]]\n",
    "\n",
    "context.set_context(mode=context.PYNATIVE_MODE, device_id=0, device_target=\"GPU\")\n",
    "\n",
    "normalize = Normalize(mean=[0.406, 0.456, 0.485], std=[0.225, 0.224, 0.229])\n",
    "transform = Compose([normalize, py_trans.ToTensor()])\n",
    "dataset = COCODataset(data_dir=\"./infer_img\",\n",
    "                      det_file_path=\"./annotation/det_json/test.json\",\n",
    "                      keypoint_num=17,\n",
    "                      flip_pairs=FLIP_PAIRS,\n",
    "                      upper_body_ids=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "                      lower_body_ids=[11, 12, 13, 14, 15, 16],\n",
    "                      input_shape=[256, 192],\n",
    "                      output_shape=[64, 48],\n",
    "                      stage='test'\n",
    "                      )\n",
    "dataloader = ds.GeneratorDataset(source=dataset,\n",
    "                                 column_names=[\"img\", \"score\", \"center\", \"scale\", \"img_id\"],\n",
    "                                 shuffle=False,\n",
    "                                 num_parallel_workers=4)\n",
    "dataloader = dataloader.map(operations=transform, input_columns=[\"img\"]).batch(32)\n",
    "\n",
    "# 实例化MSPN模型\n",
    "net = MSPN(total_stage_num=2,\n",
    "           output_channel_num=17,\n",
    "           output_shape=[64, 48],\n",
    "           upsample_channel_num=256,\n",
    "           online_hard_key_mining=True,\n",
    "           topk_keys=8,\n",
    "           coarse_to_fine=True)\n",
    "\n",
    "# 加载预训练权重\n",
    "mindspore.load_param_into_net(net, mindspore.load_checkpoint(\"mspn_new.ckpt\"))\n",
    "\n",
    "# 初始化模型\n",
    "model = mindspore.Model(net)\n",
    "\n",
    "# 开始评估\n",
    "results = compute_on_dataset(model=model,\n",
    "                             dataloader=dataloader,\n",
    "                             flip_pairs=FLIP_PAIRS,\n",
    "                             keypoint_num=17,\n",
    "                             input_shape=[256, 192],\n",
    "                             output_shape=[64, 48])\n",
    "results.sort(key=lambda res: (res['image_id'], res['score']), reverse=True)\n",
    "visualize(results=results,\n",
    "          infer_dir=\"./infer_img\",\n",
    "          save_dir=\"./res_img\",\n",
    "          score_thre=0.7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Image](./images/90891_res.jpg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 总结\n",
    "\n",
    "本案例对MSPN模型进行了详细的解释，向读者展现了算法从训练、评估到推理的完整流程，分析了MSPN中解决的若干问题。如需查看详细代码，可参考MindSpore Vision套件。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 引用\n",
    "\n",
    "[1] Wenbo Li, Zhicheng Wang, Binyi Yin, et al. Rethinking on Multi-Stage Networks for Human Pose Estimation[J]. arXiv preprint arXiv: 1901.00148v4, 2019."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}