{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 基于MobileNetV2实现分类任务\n",
    "\n",
    "## MobileNetV2简介\n",
    "\n",
    "MobileNetV2在MobileNetV1的深度可分离卷积结构的基础上，又提出了具有线性瓶颈的倒置残差结构（Inverted Residual Block），该结构先将输入的低维度的表示先扩展到高维度，然后进行轻量级深度卷积运算，最后进行线性的卷积运算将高维度表示再压缩为低维度的表示。\n",
    "\n",
    "作者之所以采用这种结构，是因为实验证明当输入的通道数很小的时候进行非线性激活会丢失很多信息。这种先扩张输入的通道数，再进行非线性激活，最后再对压缩后的输入进行线性变换的结构，可以在计算的过程中最大程度地保留有效信息，进而提高模型的分类准确率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 算法解析\n",
    "\n",
    "MobileNetV2的主要思想是希望可以用最少的参数最大程度的保留输入中的有效信息。为此，本文作者提出了三种结构来减少参数量和计算过程中的信息损失，分别是深度可分离卷积，线性瓶颈（Linear Bottlenecks），倒置残差结构。\n",
    "\n",
    "其中深度可分离卷积已在MobileNetV1中做过详细的解析，在此不再赘述。\n",
    "\n",
    "### 线性瓶颈（Linear Bottlenecks）\n",
    "\n",
    "原文中作者使用了“兴趣流形（manifold of interest）”来表示输入经过激活（activations）所获得有效信息的形态（如图1所示）。为了避免使用该专有名词解释线性瓶颈的原理可能带来的混淆，我们统一使用“有效信息”来代指“兴趣流形（manifold of interest）”。\n",
    "\n",
    "![图1](./images/Manifold_of_Interest.png)\n",
    "<center><i>图1</i></center>\n",
    "\n",
    "以ReLU激活函数（$F(x) = max(0, x)$）为例，如图1所示，使用ReLU激活时，输入的通道数越小，丢失的信息越多；反之，输入的通道越大，丢失的信息越少。\n",
    "\n",
    "举例来说，当通道数为2时，信息都集中在这两个通道中，如果有部分数值小于0就会被RELU激活丢失掉。而当通道数为30时，信息是分散且冗余的，所以使用RELU激活后归于0的值可能并不会影响太多信息的存储。如果经过ReLU激活输出是非0的，那输入和输出之间是做了一个线性变换的。换句话来说，ReLU的作用是线性分类器。\n",
    "\n",
    "综上所述，我们可以得到激活函数变换的两个属性：\n",
    "\n",
    "1. 如果有效信息在ReLU变换后仍是非0，则相当于对有效信息进行了一次线性变换。\n",
    "2. ReLU能够保留有关输入的完整有效信息的前提是输入的有效信息位于输入空间的低维子空间中（即输入空间的有效信息可以完整的映射到其低维子空间上）。\n",
    "\n",
    "针对激活函数变换的这两个属性，为了最大程度的保留输入信息中的有效信息，作者建议对于通道数较少的层做线性激活。如果需要使用ReLU激活，则需要先扩展输入的通道数再做ReLU激活。基于此，作者提出了线性瓶颈结构，如图2所示。\n",
    "\n",
    "![图2](./images/Evolution_of_Separable_Convolution_Blocks.png)\n",
    "<center><i>图2</i></center>\n",
    "\n",
    "作者通过图2展示了可分离卷积的演化过程。（a）是标准卷积；（b）是可分离卷积；（d）和（c）都是带有线性瓶颈的可分离卷积，（d）是（c）的下一个连接状态，同样是将标准卷积拆分为深度卷积和逐点卷积，再对压缩后的输入不再使用非线性激活，而是使用线性变换，防止非线性破坏过多的信息。\n",
    "\n",
    "### 倒置残差（Inverted Residual）\n",
    "\n",
    "基于我们之前对线性瓶颈的分析可知，通道数比较少的输入有效信息特别集中，而使用非线性激活会损失较多的有效信息。因此，作者想到对通道数比较少的输入进行通道数的扩张。这一点不同于传统的残差模块，传统的残差模块是先进行通道数的缩减，然后扩张通道数，由之前的分析可知，这样的结构在对通道数缩减后的输入进行非线性激活时会损失大量的有效信息。\n",
    "\n",
    "作者通过对传统的残差模块进行倒置，从而减少了模型的有效信息的损失。同时，使用捷径（shortcut）结构还是可以发挥和传统的残差模型一样的作用，提高模型中模块之间梯度传播的能力。传统残差模块和倒置残差模块的结构对比如图3所示。\n",
    "\n",
    "![图3](./images/Inverted_Residual_Block.png)\n",
    "<center><i>图3</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 模型结构\n",
    "\n",
    "下面我们通过MindSpore vision套件来剖析MobileNetV2的结构，相关模块在Vision套件中都有API可直接调用。\n",
    "\n",
    "### ConvNormActivation结构\n",
    "\n",
    "ConvNormActivation模块是所有卷积网络中最基础的模块，由一个卷积层（Conv, Depwise Conv），一个归一化层(BN)，一个激活函数组成。图2中可以套用这个结构的的小模块：Depwise Conv+BN+ReLU6，Pointwise Conv+BN+ReLU6。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "from mindspore import nn\n",
    "\n",
    "\n",
    "class ConvNormActivation(nn.Cell):\n",
    "    \"\"\"\n",
    "    Convolution/Depthwise fused with normalization and activation\n",
    "    blocks definition.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_planes: int,\n",
    "                 out_planes: int,\n",
    "                 kernel_size: int = 3,\n",
    "                 stride: int = 1,\n",
    "                 groups: int = 1,\n",
    "                 norm: Optional[nn.Cell] = nn.BatchNorm2d,\n",
    "                 activation: Optional[nn.Cell] = nn.ReLU\n",
    "                 ) -> None:\n",
    "        super(ConvNormActivation, self).__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        # 设置和添加卷积层\n",
    "        layers = [\n",
    "            nn.Conv2d(\n",
    "                in_planes,\n",
    "                out_planes,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                pad_mode='pad',\n",
    "                padding=padding,\n",
    "                group=groups\n",
    "            )\n",
    "        ]\n",
    "        # 判断是否设置归一化层\n",
    "        if norm:\n",
    "            # 设置归一化层\n",
    "            layers.append(norm(out_planes))\n",
    "        # 判断是否设置激活函数\n",
    "        if activation:\n",
    "            # 设置激活函数\n",
    "            layers.append(activation())\n",
    "\n",
    "        self.features = nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        output = self.features(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 倒置残差结构（Inverted Residual Block）\n",
    "\n",
    "MobileNetv2模型的基础结构是Inverted Residual Block，其结构图如图3（b）所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mindspore.ops.operations import Add\n",
    "\n",
    "from mindvision.classification.models.blocks import ConvNormActivation\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Cell):\n",
    "    \"\"\"\n",
    "    Mobilenetv2 residual block definition.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channel: int,\n",
    "                 out_channel: int,\n",
    "                 stride: int,\n",
    "                 expand_ratio: int,\n",
    "                 norm: Optional[nn.Cell] = None,\n",
    "                 last_relu: bool = False\n",
    "                 ) -> None:\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        if not norm:\n",
    "            norm = nn.BatchNorm2d\n",
    "\n",
    "        hidden_dim = round(in_channel * expand_ratio)\n",
    "        self.use_res_connect = stride == 1 and in_channel == out_channel\n",
    "\n",
    "        layers: List[nn.Cell] = []\n",
    "        if expand_ratio != 1:\n",
    "            # pw\n",
    "            layers.append(\n",
    "                ConvNormActivation(in_channel, hidden_dim, kernel_size=1,\n",
    "                                   norm=norm, activation=nn.ReLU6)\n",
    "            )\n",
    "        layers.extend([\n",
    "            # dw\n",
    "            ConvNormActivation(\n",
    "                hidden_dim,\n",
    "                hidden_dim,\n",
    "                stride=stride,\n",
    "                groups=hidden_dim,\n",
    "                norm=norm,\n",
    "                activation=nn.ReLU6\n",
    "            ),\n",
    "            # pw-linear\n",
    "            nn.Conv2d(hidden_dim, out_channel, kernel_size=1,\n",
    "                      stride=1, has_bias=False),\n",
    "            norm(out_channel)\n",
    "        ])\n",
    "        self.conv = nn.SequentialCell(layers)\n",
    "        self.add = Add()\n",
    "        self.last_relu = last_relu\n",
    "        self.relu = nn.ReLU6()\n",
    "\n",
    "    def construct(self, x):\n",
    "        identity = x\n",
    "        x = self.conv(x)\n",
    "        if self.use_res_connect:\n",
    "            x = self.add(identity, x)\n",
    "        if self.last_relu:\n",
    "            x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 基准模型结构\n",
    "\n",
    "MobileNetV2的主体结构的各项参数如图4所示。\n",
    "\n",
    "![图4](./images/MobileNetV2_Structure.png)\n",
    "<center><i>图4</i></center>\n",
    "\n",
    "根据图4的参数，我们构造了MobileNetV2的主体结构，如下面的代码所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mindvision.classification.models.utils import make_divisible\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Cell):\n",
    "    \"\"\"\n",
    "    MobileNetV2 architecture.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 alpha: float = 1.0,\n",
    "                 inverted_residual_setting: Optional[List[List[int]]] = None,\n",
    "                 round_nearest: int = 8,\n",
    "                 block: Optional[nn.Cell] = None,\n",
    "                 norm: Optional[nn.Cell] = None,\n",
    "                 ) -> None:\n",
    "        super(MobileNetV2, self).__init__()\n",
    "\n",
    "        if not block:\n",
    "            block = InvertedResidual\n",
    "        if not norm:\n",
    "            norm = nn.BatchNorm2d\n",
    "\n",
    "        input_channel = make_divisible(32 * alpha, round_nearest)\n",
    "        last_channel = make_divisible(1280 * max(1.0, alpha), round_nearest)\n",
    "\n",
    "        # Setting of inverted residual blocks.\n",
    "        if not inverted_residual_setting:\n",
    "            inverted_residual_setting = [\n",
    "                # t, c, n, s\n",
    "                [1, 16, 1, 1],\n",
    "                [6, 24, 2, 2],\n",
    "                [6, 32, 3, 2],\n",
    "                [6, 64, 4, 2],\n",
    "                [6, 96, 3, 1],\n",
    "                [6, 160, 3, 2],\n",
    "                [6, 320, 1, 1],\n",
    "            ]\n",
    "\n",
    "        # Building first layer.\n",
    "        features: List[nn.Cell] = [\n",
    "            ConvNormActivation(3, input_channel, stride=2, norm=norm, activation=nn.ReLU6)\n",
    "        ]\n",
    "\n",
    "        # Building inverted residual blocks.\n",
    "        # t: The expansion factor.\n",
    "        # c: Number of output channel.\n",
    "        # n: Number of block.\n",
    "        # s: First block stride.\n",
    "        for t, c, n, s in inverted_residual_setting:\n",
    "            output_channel = make_divisible(c * alpha, round_nearest)\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                features.append(block(input_channel, output_channel, stride,\n",
    "                                      expand_ratio=t, norm=norm))\n",
    "                input_channel = output_channel\n",
    "\n",
    "        # Building last several layers.\n",
    "        features.append(\n",
    "            ConvNormActivation(input_channel, last_channel, kernel_size=1,\n",
    "                               norm=norm, activation=nn.ReLU6)\n",
    "        )\n",
    "        # Make it nn.CellList.\n",
    "        self.features = nn.SequentialCell(features)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.features(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MobileNetV2模型\n",
    "\n",
    "基于MobileNetV2的主体结构，我们构造了MobileNetV2分类模型，代码如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mindvision.classification.models.classifiers import BaseClassifier\n",
    "from mindvision.classification.models.head import ConvHead\n",
    "from mindvision.classification.models.neck import GlobalAvgPooling\n",
    "from mindvision.classification.utils.model_urls import model_urls\n",
    "from mindvision.utils.load_pretrained_model import LoadPretrainedModel\n",
    "\n",
    "\n",
    "def mobilenet_v2(num_classes: int = 1001,\n",
    "                 alpha: float = 1.0,\n",
    "                 round_nearest: int = 8,\n",
    "                 pretrained: bool = False,\n",
    "                 resize: int = 224,\n",
    "                 block: Optional[nn.Cell] = None,\n",
    "                 norm: Optional[nn.Cell] = None,\n",
    "                 ) -> MobileNetV2:\n",
    "    \"\"\"\n",
    "    Constructs a MobileNetV2 architecture from\n",
    "    `MobileNetV2: Inverted Residuals and Linear Bottlenecks\n",
    "    <https://arxiv.org/abs/1801.04381>`_.\n",
    "    \"\"\"\n",
    "    backbone = MobileNetV2(alpha=alpha, round_nearest=round_nearest, block=block, norm=norm)\n",
    "    neck = GlobalAvgPooling(keep_dims=True)\n",
    "    inp_channel = make_divisible(1280 * max(1.0, alpha), round_nearest)\n",
    "    head = ConvHead(input_channel=inp_channel, num_classes=num_classes)\n",
    "    model = BaseClassifier(backbone, neck, head)\n",
    "\n",
    "    if pretrained:\n",
    "        # Download the pre-trained checkpoint file from url, and load\n",
    "        # checkpoint file.\n",
    "        arch = \"mobilenet_v2_\" + str(alpha) + \"_\" + str(resize)\n",
    "        LoadPretrainedModel(model, model_urls[arch]).run()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 模型训练与推理\n",
    "\n",
    "本案例基于MindSpore-GPU版本，在单GPU卡上完成模型训练和验证。\n",
    "\n",
    "首先导入相关模块，配置相关超参数并读取数据集，该部分代码在Vision套件中都有API可直接调用，详情可以参考以下链接：https://gitee.com/mindspore/vision 。\n",
    "\n",
    "可通过:http://image-net.org/ 进行数据集下载。\n",
    "\n",
    "加载前先定义数据集路径，请确保你的数据集路径如以下结构。\n",
    "\n",
    "```text\n",
    ".ImageNet/\n",
    "    ├── ILSVRC2012_devkit_t12.tar.gz\n",
    "    ├── train/\n",
    "    ├── val/\n",
    "    └── mobilenetv2_infer.png\n",
    "```\n",
    "\n",
    "### 模型训练\n",
    "\n",
    "训练模型前，需要先按照论文中给出的参数设置损失函数，优化器以及回调函数，MindSpore Vision套件提供了提供了相应的接口，具体代码如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from mindspore import context\n",
    "from mindspore.common import set_seed\n",
    "from mindspore.communication import init, get_rank, get_group_size\n",
    "from mindspore.context import ParallelMode\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig\n",
    "\n",
    "from mindvision.classification.dataset import ImageNet\n",
    "from mindvision.engine.loss import CrossEntropySmooth\n",
    "from mindvision.engine.callback import LossMonitor\n",
    "\n",
    "set_seed(1)\n",
    "\n",
    "\n",
    "def mobilenet_v2_train(args_opt):\n",
    "    \"\"\"MobileNetV2 train.\"\"\"\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=args_opt.device_target)\n",
    "\n",
    "    # Data Pipeline.\n",
    "    if args_opt.run_distribute:\n",
    "        init(\"nccl\")\n",
    "        rank_id = get_rank()\n",
    "        device_num = get_group_size()\n",
    "        context.set_auto_parallel_context(device_num=device_num,\n",
    "                                          parallel_mode=ParallelMode.DATA_PARALLEL,\n",
    "                                          gradients_mean=True)\n",
    "        dataset = ImageNet(args_opt.data_url,\n",
    "                           split=\"train\",\n",
    "                           num_parallel_workers=args_opt.num_parallel_workers,\n",
    "                           shuffle=True,\n",
    "                           resize=args_opt.resize,\n",
    "                           num_shards=device_num,\n",
    "                           shard_id=rank_id,\n",
    "                           batch_size=args_opt.batch_size,\n",
    "                           repeat_num=args_opt.repeat_num)\n",
    "        ckpt_save_dir = args_opt.ckpt_save_dir + \"_ckpt_\" + str(rank_id) + \"/\"\n",
    "    else:\n",
    "        dataset = ImageNet(args_opt.data_url,\n",
    "                           split=\"train\",\n",
    "                           num_parallel_workers=args_opt.num_parallel_workers,\n",
    "                           shuffle=True,\n",
    "                           resize=args_opt.resize,\n",
    "                           batch_size=args_opt.batch_size,\n",
    "                           repeat_num=args_opt.repeat_num)\n",
    "        ckpt_save_dir = args_opt.ckpt_save_dir\n",
    "\n",
    "    dataset_train = dataset.run()\n",
    "    step_size = dataset_train.get_dataset_size()\n",
    "\n",
    "    # Create model.\n",
    "    network = mobilenet_v2(args_opt.num_classes, alpha=args_opt.alpha, pretrained=args_opt.pretrained,\n",
    "                           resize=args_opt.resize)\n",
    "\n",
    "    # Set lr scheduler.\n",
    "    if args_opt.lr_decay_mode == 'cosine_decay_lr':\n",
    "        lr = nn.cosine_decay_lr(min_lr=args_opt.min_lr, max_lr=args_opt.max_lr,\n",
    "                                total_step=args_opt.epoch_size * step_size, step_per_epoch=step_size,\n",
    "                                decay_epoch=args_opt.decay_epoch)\n",
    "    elif args_opt.lr_decay_mode == 'piecewise_constant_lr':\n",
    "        lr = nn.piecewise_constant_lr(args_opt.milestone, args_opt.learning_rates)\n",
    "\n",
    "    # Define optimizer.\n",
    "    network_opt = nn.Momentum(network.trainable_params(), lr, args_opt.momentum)\n",
    "\n",
    "    # Define loss function.\n",
    "    network_loss = CrossEntropySmooth(sparse=True, reduction=\"mean\", smooth_factor=args_opt.smooth_factor,\n",
    "                                      classes_num=args_opt.num_classes)\n",
    "    # Define metrics.\n",
    "    metrics = {'acc'}\n",
    "\n",
    "    # Set the checkpoint config for the network.\n",
    "    ckpt_config = CheckpointConfig(\n",
    "        save_checkpoint_steps=step_size,\n",
    "        keep_checkpoint_max=args_opt.keep_checkpoint_max)\n",
    "    ckpt_callback = ModelCheckpoint(prefix='mobilenet_v2',\n",
    "                                    directory=ckpt_save_dir,\n",
    "                                    config=ckpt_config)\n",
    "    # Init the model.\n",
    "    model = Model(network, loss_fn=network_loss, optimizer=network_opt, metrics=metrics)\n",
    "\n",
    "    # Begin to train.\n",
    "    model.train(args_opt.epoch_size,\n",
    "                dataset_train,\n",
    "                callbacks=[ckpt_callback, LossMonitor(lr)],\n",
    "                dataset_sink_mode=args_opt.dataset_sink_mode)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='MobileNetV2 train.')\n",
    "    parser.add_argument('--device_target', type=str, default=\"GPU\", choices=[\"Ascend\", \"GPU\", \"CPU\"])\n",
    "    parser.add_argument('--data_url', required=True, default=None, help='Location of data.')\n",
    "    parser.add_argument('--epoch_size', type=int, default=200, help='Train epoch size.')\n",
    "    parser.add_argument('--pretrained', type=bool, default=False, help='Load pretrained model.')\n",
    "    parser.add_argument('--keep_checkpoint_max', type=int, default=10, help='Max number of checkpoint files.')\n",
    "    parser.add_argument('--ckpt_save_dir', type=str, default=\"./mobilenet_v2\", help='Location of training outputs.')\n",
    "    parser.add_argument('--num_parallel_workers', type=int, default=8, help='Number of parallel workers.')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, help='Number of batch size.')\n",
    "    parser.add_argument('--repeat_num', type=int, default=1, help='Number of repeat.')\n",
    "    parser.add_argument('--num_classes', type=int, default=1001, help='Number of classification.')\n",
    "    parser.add_argument('--lr_decay_mode', type=str, default=\"cosine_decay_lr\", help='Learning rate decay mode.')\n",
    "    parser.add_argument('--min_lr', type=float, default=0.0, help='The minimum learning rate.')\n",
    "    parser.add_argument('--max_lr', type=float, default=0.1, help='The maximum learning rate.')\n",
    "    parser.add_argument('--decay_epoch', type=int, default=200, help='Number of decay epochs.')\n",
    "    parser.add_argument('--milestone', type=list, default=None, help='A list of milestone.')\n",
    "    parser.add_argument('--learning_rates', type=list, default=None, help='A list of learning rates.')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, help='Momentum for the moving average.')\n",
    "    parser.add_argument('--smooth_factor', type=float, default=0.1, help='Label smoothing factor.')\n",
    "    parser.add_argument('--dataset_sink_mode', type=bool, default=True, help='The dataset sink mode.')\n",
    "    parser.add_argument('--run_distribute', type=bool, default=True, help='Distributed parallel training.')\n",
    "    parser.add_argument('--alpha', type=float, default=1.0, help='Magnification factor.')\n",
    "    parser.add_argument('--resize', type=int, default=224, help='Resize the height and weight of picture.')\n",
    "\n",
    "    args = parser.parse_known_args()[0]\n",
    "    mobilenet_v2_train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "运行如下脚本，即可开始训练MobileNetV2模型。\n",
    "\n",
    "```shell\n",
    "mpirun -n 8 python mobilenet_v2_imagenet_train.py --alpha 1.0 --resize 224 --data_url ./dataset/imagenet\n",
    "```\n",
    "\n",
    "```text\n",
    "Epoch:[0/200], step:[2502/2502], loss:[4.676/4.676], time:872084.093, lr:0.10000\n",
    "Epoch time:883614.453, per step time:353.163, avg loss:4.676\n",
    "Epoch:[1/200], step:[2502/2502], loss:[4.452/4.452], time:693370.244, lr:0.09998\n",
    "Epoch time:693374.709, per step time:277.128, avg loss:4.452\n",
    "Epoch:[2/200], step:[2502/2502], loss:[3.885/3.885], time:685880.388, lr:0.09990\n",
    "Epoch time:685884.401, per step time:274.134, avg loss:3.885\n",
    "Epoch:[3/200], step:[2502/2502], loss:[3.550/3.550], time:689409.851, lr:0.09978\n",
    "Epoch time:689413.237, per step time:275.545, avg loss:3.550\n",
    "Epoch:[4/200], step:[2502/2502], loss:[3.371/3.371], time:692162.583, lr:0.09961\n",
    "Epoch time:692166.163, per step time:276.645, avg loss:3.371\n",
    "...\n",
    "```\n",
    "\n",
    "### 模型验证\n",
    "\n",
    "模型验证过程与训练过程相似。不同的是验证过程不需要设置优化器，但是需要设置评价指标\n",
    "\n",
    "调用ImageNet验证集数据的只需要将接口的split参数设置为\"val\"即可，具体代码如下所示。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mobilenet_v2_eval(args_opt):\n",
    "    \"\"\"MobileNetV2 eval.\"\"\"\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=args_opt.device_target)\n",
    "\n",
    "    # Data pipeline.\n",
    "    dataset_path = args_opt.data_url\n",
    "\n",
    "    dataset = ImageNet(dataset_path,\n",
    "                       split=\"val\",\n",
    "                       num_parallel_workers=args_opt.num_parallel_workers,\n",
    "                       resize=args_opt.resize,\n",
    "                       batch_size=args_opt.batch_size)\n",
    "\n",
    "    dataset_eval = dataset.run()\n",
    "\n",
    "    # Create model.\n",
    "    network = mobilenet_v2(args_opt.num_classes, alpha=args_opt.alpha, pretrained=args_opt.pretrained,\n",
    "                           resize=args_opt.resize)\n",
    "\n",
    "    # Define loss function.\n",
    "    network_loss = CrossEntropySmooth(sparse=True, reduction=\"mean\", smooth_factor=args_opt.smooth_factor,\n",
    "                                      classes_num=args_opt.num_classes)\n",
    "\n",
    "    # Define eval metrics.\n",
    "    eval_metrics = {'Top_1_Accuracy': nn.Top1CategoricalAccuracy(),\n",
    "                    'Top_5_Accuracy': nn.Top5CategoricalAccuracy()}\n",
    "\n",
    "    # Init the model.\n",
    "    model = Model(network, network_loss, metrics=eval_metrics)\n",
    "\n",
    "    # Begin to eval\n",
    "    result = model.eval(dataset_eval)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='MobileNetV2 eval.')\n",
    "    parser.add_argument('--device_target', type=str, default=\"GPU\", choices=[\"Ascend\", \"GPU\", \"CPU\"])\n",
    "    parser.add_argument('--data_url', required=True, default=None, help='Location of data.')\n",
    "    parser.add_argument('--pretrained', type=bool, default=False, help='Load pretrained model.')\n",
    "    parser.add_argument('--num_parallel_workers', type=int, default=8, help='Number of parallel workers.')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, help='Number of batch size.')\n",
    "    parser.add_argument('--num_classes', type=int, default=1001, help='Number of classification.')\n",
    "    parser.add_argument('--smooth_factor', type=float, default=0.1, help='The smooth factor.')\n",
    "    parser.add_argument('--alpha', type=float, default=1.0, help='Magnification factor.')\n",
    "    parser.add_argument('--resize', type=int, default=224, help='Resize the height and weight of picture.')\n",
    "\n",
    "    args = parser.parse_known_args()[0]\n",
    "    mobilenet_v2_eval(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "运行如下脚本，即可开始验证MobileNetV2模型的精度。\n",
    "\n",
    "```shell\n",
    "python mobilenet_v2_imagenet_eval.py --alpha 0.75 --resize 192 --pretrained True --data_url ./dataset/imagenet\n",
    "```\n",
    "\n",
    "```text\n",
    "{'Top_1_Accuracy': 0.6922876602564103, 'Top_5_Accuracy': 0.8871594551282052}\n",
    "```\n",
    "\n",
    "使用MindSpore Vision套件的MobileNetV2的Top-1 Accuracy和Top-5 Accuracy与使用TensorFlow的对比，如下图所示：\n",
    "\n",
    "<div align=center><img src=\"./images/mobilenetv2_accuracy.png\"></div>\n",
    "\n",
    "### 模型推理\n",
    "\n",
    "模型的推理过程较为简单，只需要使用ImageNet数据集接口读取要推理的图片，加载预训练网络，通过Model.predict方法对图片进行推理即可，具体代码如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from mindspore import Tensor\n",
    "\n",
    "from mindvision.classification.utils.image import show_result\n",
    "from mindvision.dataset.download import read_dataset\n",
    "\n",
    "\n",
    "def mobilenet_v2_infer(args_opt):\n",
    "    \"\"\"MobileNetV2 infer.\"\"\"\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=args_opt.device_target)\n",
    "\n",
    "    # Data pipeline.\n",
    "    dataset = ImageNet(args_opt.data_url,\n",
    "                       split=\"infer\",\n",
    "                       num_parallel_workers=args_opt.num_parallel_workers,\n",
    "                       resize=args_opt.resize,\n",
    "                       batch_size=args_opt.batch_size)\n",
    "\n",
    "    dataset_infer = dataset.run()\n",
    "\n",
    "    # Create model.\n",
    "    network = mobilenet_v2(args_opt.num_classes, alpha=args_opt.alpha, pretrained=args_opt.pretrained,\n",
    "                           resize=args_opt.resize)\n",
    "\n",
    "    # Init the model.\n",
    "    model = Model(network)\n",
    "\n",
    "    # Begin to infer\n",
    "    image_list, _ = read_dataset(args_opt.data_url)\n",
    "    for data in dataset_infer.create_dict_iterator(output_numpy=True):\n",
    "        image = data[\"image\"]\n",
    "        image = Tensor(image)\n",
    "        prob = model.predict(image)\n",
    "        label = np.argmax(prob.asnumpy(), axis=1)\n",
    "        for i, v in enumerate(label):\n",
    "            predict = dataset.index2label[v]\n",
    "            output = {v: predict}\n",
    "            print(output)\n",
    "            show_result(img=image_list[i], result=output, out_file=image_list[i])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='MobileNetV2 infer.')\n",
    "    parser.add_argument('--device_target', type=str, default=\"GPU\", choices=[\"Ascend\", \"GPU\", \"CPU\"])\n",
    "    parser.add_argument('--data_url', required=True, default=None,\n",
    "                        help='Root of infer data and ILSVRC2012_devkit_t12.tar.gz.')\n",
    "    parser.add_argument('--pretrained', type=bool, default=False, help='Load pretrained model.')\n",
    "    parser.add_argument('--num_parallel_workers', type=int, default=8, help='Number of parallel workers.')\n",
    "    parser.add_argument('--batch_size', type=int, default=1, help='Number of batch size.')\n",
    "    parser.add_argument('--num_classes', type=int, default=1001, help='Number of classification.')\n",
    "    parser.add_argument('--alpha', type=float, default=1.0, help='Magnification factor.')\n",
    "    parser.add_argument('--resize', type=int, default=224, help='Resize the height and weight of picture.')\n",
    "\n",
    "    args = parser.parse_known_args()[0]\n",
    "    mobilenet_v2_infer(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "运行如下脚本，即可开始使用MobileNetV2模型对目标图片进行推理。\n",
    "\n",
    "```shell\n",
    "python mobilenet_v2_imagenet_infer.py --alpha 1.0 --resize 224 --pretrained True --data_url ./infer\n",
    "```\n",
    "\n",
    "```text\n",
    "{283: 'Persian cat'}\n",
    "```\n",
    "\n",
    "<div align=center><img src=\"./images/mobilenetv2_infer.jpg\"></div>\n",
    "\n",
    "## 总结\n",
    "\n",
    "本案例对MobileNetV2的论文中提出的具有线性瓶颈的倒置残差结构（Inverted Residual Block）进行了详细的解释，向读者完整地呈现了该结构提出的背景以及理论依据。\n",
    "\n",
    "同时，通过MindSpore Vision套件，剖析了MobileNetV2的主要模块和主体结构，还完成了MobileNetV2模型在ImageNet数据上的训练，验证和推理的过程，如需完整的源码可以参考[MindSpore Vision套件](https://gitee.com/mindspore/vision/tree/master/examples/classification/mobilenetv2)。\n",
    "\n",
    "## 引用\n",
    "\n",
    "[1] Sandler M, Howard A, Zhu M, et al. Mobilenetv2: Inverted residuals and linear bottlenecks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2018: 4510-4520."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
