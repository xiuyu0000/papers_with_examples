{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 基于MobileNet V1实现分类任务\n",
    "\n",
    "## MobileNet简介\n",
    "\n",
    "MobileNet是用于移动和嵌入式视觉应用的高效模型。MobileNet基于流线型架构，该架构使用深度可分离卷积来构建轻量级深度神经网络。MobileNet模型引入了两个全局超参数（宽度因子和分辨率因子）来平衡模型处理数据的速度和模型的精度。基于对模型的处理速度和模型的精度的灵活的掌控，MobileNets可以适应非常广阔的应用场景，包括对象检测、细粒度分类、人脸属性和大规模地理定位。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 算法解析\n",
    "\n",
    "MobileNet的主要特点是高效和适用广泛。MobileNet模型的基础结构——深度可分离卷积，保证了模型的高效；设置宽度因子和分辨率因子保证了模型的适应性强。\n",
    "\n",
    "### 深度可分离卷积\n",
    "\n",
    "深度可分离卷积是可分解卷积的一种形式，将标注的卷积分解为深度卷积和逐点卷积。\n",
    "\n",
    "![图1](./images/Depthwise_Separable_Conv.png)\n",
    "<center><i>图1</i></center>\n",
    "\n",
    "#### 深度卷积（Depthwise Conv）\n",
    "\n",
    "深度卷积（如图1（b）所示）为每个输入通道应用一个滤波器，然后将每个输入通道与相应的滤波器进行卷积，最后将卷积输出堆叠在一起。深度卷价的计算成本为：\n",
    "\n",
    "$$\n",
    "Cost_{dw-conv} = D_K \\cdot D_K \\cdot M \\cdot D_F \\cdot D_F \\tag{1}\n",
    "$$\n",
    "\n",
    "#### 逐点卷积（Pointwise Conv）\n",
    "\n",
    "逐点卷积（如图1（c）所示）是一种使用1x1内核的卷积，内核的深度就等于图像的通道数。逐点卷积的计算成本为：\n",
    "\n",
    "$$\n",
    "Cost_{pw-conv} = M \\cdot N \\cdot D_F \\cdot D_F \\tag{2}\n",
    "$$\n",
    "\n",
    "标准卷积在一个步骤中同时执行通道和空间计算，而深度可分离卷积将计算分为两个步骤：深度卷积对每个输入通道应用一个卷积滤波器，逐点卷积将深度卷积的输出进行线性组合。标准卷积和深度可分离卷积的比较如图2所示。\n",
    "\n",
    "![图2](./images/Depthwise_Separable_Structure.png)\n",
    "<center><i>图2</i></center>\n",
    "\n",
    "![图3](./images/Standard_Conv_vs_Depthwise_Separable_Conv.png)\n",
    "<center><i>图3</i></center>\n",
    "\n",
    "标准卷积的计算成本为：\n",
    "\n",
    "$$\n",
    "Cost_{standard-conv} = D_K \\cdot D_K \\cdot M \\cdot N \\cdot D_F \\cdot D_F \\tag{3}\n",
    "$$\n",
    "\n",
    "其中，$D_K$是depthwise_conv的kernel size，$M$是输入的通道数，$N$是输入的batch size，$D_F$是feature map的size。\n",
    "\n",
    "深度可分离卷积的计算成本为：\n",
    "\n",
    "$$\n",
    "Cost_{depthwise-separable-conv} = D_K \\cdot D_K \\cdot M \\cdot D_F \\cdot D_F + M \\cdot N \\cdot D_F \\cdot D_F \\tag{4}\n",
    "$$\n",
    "\n",
    "综上所述，我们可以比较深度可分离卷积的计算成本与标准卷积的计算成本：\n",
    "\n",
    "$$\n",
    "\\cfrac{Cost_{depthwise-separable-conv} }{Cost_{standard-conv}} = \\cfrac{D_K \\cdot D_K \\cdot M \\cdot D_F \\cdot D_F + M \\cdot N \\cdot D_F \\cdot D_F}{D_K \\cdot D_K \\cdot M \\cdot N \\cdot D_F \\cdot D_F} = \\cfrac{1}{N} + \\cfrac{1}{D_K^2} \\tag{5}\n",
    "$$\n",
    "\n",
    "一般数据集的batch_size较大，所以$\\cfrac{1}{N}$对该比例的影响较小，因此该比例可以简化为：\n",
    "\n",
    "$$\n",
    "\\cfrac{Cost_{depthwise-separable-conv} }{Cost_{standard-conv}} \\approx \\cfrac{1}{D_K^2} \\tag{6}\n",
    "$$\n",
    "\n",
    "由于MobileNet的kernel size为3，也即使用深度可分离卷积的计算成本是标准卷积的1/9。与此同时，由于一般图片的空间位置高度相关，不同通道之间相对独立，所以这种方式对精度的影响非常的小。\n",
    "\n",
    "### 模型缩放\n",
    "\n",
    "MobileNet主要通过设置宽度因子和分辨率因子来对模型进行缩放。\n",
    "\n",
    "#### 宽度因子\n",
    "\n",
    "虽然MobileNet的基准模型已经足够小和足够快了。但是很多时候是一些特定的用例或应用程序可能要求模型更小更快。为了构建这些更小且计算量更少的模型，MobileNet引入了一个非常简单的参数α，我们称为宽度因子。宽度因子会缩短每层输入和输出的宽度，从而构建更小更快的模型。\n",
    "\n",
    "考虑宽度因子 $\\alpha$ 的深度可分离卷积的计算成本为：\n",
    "\n",
    "$$\n",
    "Cost_{\\alpha-depthwise-separable-conv} = D_K \\cdot D_K \\cdot \\alpha M \\cdot D_F \\cdot D_F + \\alpha M \\cdot \\alpha N \\cdot D_F \\cdot D_F \\tag{6}\n",
    "$$\n",
    "\n",
    "其中，$\\alpha \\in [0.25, 0.50, 0.75, 1.00]$。\n",
    "\n",
    "#### 分辨率因子\n",
    "\n",
    "分辨率因子是作用于每一个模块输入尺寸的约减因子，简单来说就是将输入数据以及由此在每一个模块产生的特征图都变小了，结合宽度因子 $\\alpha$ 和分辨率因子 $\\rho$ 的深度可分离卷积的计算成本为：\n",
    "\n",
    "$$\n",
    "Cost_{\\alpha-\\rho-depthwise-separable-conv} = D_K \\cdot D_K \\cdot \\alpha M \\cdot \\rho D_F \\cdot \\rho D_F + \\alpha M \\cdot \\alpha N \\cdot \\rho D_F \\cdot \\rho D_F\n",
    "$$\n",
    "\n",
    "其中，$\\rho D_F \\in [224, 192, 160, 128]$。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 模型结构\n",
    "\n",
    "下面我们通过MindSpore vision套件来剖析MobileNet的结构，相关模块在Vision套件中都有API可直接调用。\n",
    "\n",
    "### ConvNormActivation结构\n",
    "\n",
    "ConvNormActivation模块是所有卷积网络中最基础的模块，由一个卷积层（Conv, Depwise Conv），一个归一化层(BN)，一个激活函数组成。图2中可以套用这个结构的的小模块：Depwise Conv+BN+ReLU6，Pointwise Conv+BN+ReLU6。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from mindspore import nn\n",
    "\n",
    "class ConvNormActivation(nn.Cell):\n",
    "    \"\"\"\n",
    "    Convolution/Depthwise fused with normalization and activation blocks definition.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_planes: int,\n",
    "                 out_planes: int,\n",
    "                 kernel_size: int = 3,\n",
    "                 stride: int = 1,\n",
    "                 groups: int = 1,\n",
    "                 norm: Optional[nn.Cell] = nn.BatchNorm2d,\n",
    "                 activation: Optional[nn.Cell] = nn.ReLU\n",
    "                 ) -> None:\n",
    "        super(ConvNormActivation, self).__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        # 设置和添加卷积层\n",
    "        layers = [\n",
    "            nn.Conv2d(\n",
    "                in_planes,\n",
    "                out_planes,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                pad_mode='pad',\n",
    "                padding=padding,\n",
    "                group=groups\n",
    "            )\n",
    "        ]\n",
    "        # 判断是否设置归一化层\n",
    "        if norm:\n",
    "            # 设置归一化层\n",
    "            layers.append(norm(out_planes))\n",
    "        # 判断是否设置激活函数\n",
    "        if activation:\n",
    "            # 设置激活函数\n",
    "            layers.append(activation())\n",
    "\n",
    "        self.features = nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        output = self.features(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 基准模型结构\n",
    "\n",
    "MobileNetV1的主体结构的各项参数如图4所示。\n",
    "\n",
    "![图4](./images/MobileNet_BackBone_Architeture.png)\n",
    "<center><i>图4</i></center>\n",
    "\n",
    "根据图4的参数，我们构造了MobileNetVM的主体结构，如下面的代码所示。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mindvision.classification.models.classifiers import BaseClassifier\n",
    "from mindvision.classification.models.blocks import ConvNormActivation\n",
    "\n",
    "\n",
    "class MobileNetV1(nn.Cell):\n",
    "    \"\"\"\n",
    "    MobileNet V1 backbone.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ):\n",
    "        super(MobileNetV1, self).__init__()\n",
    "        self.layers = [\n",
    "            ConvNormActivation(3, 32, 3, 2, activation=nn.ReLU6),  # Conv0\n",
    "\n",
    "            ConvNormActivation(32, 32, 3, 1, groups=32, activation=nn.ReLU6),  # Conv1_depthwise\n",
    "            ConvNormActivation(32, 64, 1, 1, activation=nn.ReLU6),  # Conv1_pointwise\n",
    "            ConvNormActivation(64, 64, 3, 2, groups=64, activation=nn.ReLU6),  # Conv2_depthwise\n",
    "            ConvNormActivation(64, 128, 1, 1, activation=nn.ReLU6),  # Conv2_pointwise\n",
    "\n",
    "            ConvNormActivation(128, 128, 3, 1, groups=128, activation=nn.ReLU6),  # Conv3_depthwise\n",
    "            ConvNormActivation(128, 128, 1, 1, activation=nn.ReLU6),  # Conv3_pointwise\n",
    "            ConvNormActivation(128, 128, 3, 2, groups=128, activation=nn.ReLU6),  # Conv4_depthwise\n",
    "            ConvNormActivation(128, 256, 1, 1, activation=nn.ReLU6),  # Conv4_pointwise\n",
    "\n",
    "            ConvNormActivation(256, 256, 3, 1, groups=256, activation=nn.ReLU6),  # Conv5_depthwise\n",
    "            ConvNormActivation(256, 256, 1, 1, activation=nn.ReLU6),  # Conv5_pointwise\n",
    "            ConvNormActivation(256, 256, 3, 2, groups=256, activation=nn.ReLU6),  # Conv6_depthwise\n",
    "            ConvNormActivation(256, 512, 1, 1, activation=nn.ReLU6),  # Conv6_pointwise\n",
    "\n",
    "            ConvNormActivation(512, 512, 3, 1, groups=512, activation=nn.ReLU6),  # Conv7_depthwise\n",
    "            ConvNormActivation(512, 512, 1, 1, activation=nn.ReLU6),  # Conv7_pointwise\n",
    "            ConvNormActivation(512, 512, 3, 1, groups=512, activation=nn.ReLU6),  # Conv8_depthwise\n",
    "            ConvNormActivation(512, 512, 1, 1, activation=nn.ReLU6),  # Conv8_pointwise\n",
    "            ConvNormActivation(512, 512, 3, 1, groups=512, activation=nn.ReLU6),  # Conv9_depthwise\n",
    "            ConvNormActivation(512, 512, 1, 1, activation=nn.ReLU6),  # Conv9_pointwise\n",
    "            ConvNormActivation(512, 512, 3, 1, groups=512, activation=nn.ReLU6),  # Conv10_depthwise\n",
    "            ConvNormActivation(512, 512, 1, 1, activation=nn.ReLU6),  # Conv10_pointwise\n",
    "            ConvNormActivation(512, 512, 3, 1, groups=512, activation=nn.ReLU6),  # Conv11_depthwise\n",
    "            ConvNormActivation(512, 512, 1, 1, activation=nn.ReLU6),  # Conv11_pointwise\n",
    "\n",
    "            ConvNormActivation(512, 512, 3, 2, groups=512, activation=nn.ReLU6),  # Conv12_depthwise\n",
    "            ConvNormActivation(512, 1024, 1, 1, activation=nn.ReLU6),  # Conv12_pointwise\n",
    "            ConvNormActivation(1024, 1024, 3, 1, groups=1024, activation=nn.ReLU6),  # Conv13_depthwise\n",
    "            ConvNormActivation(1024, 1024, 1, 1, activation=nn.ReLU6),  # Conv13_pointwise\n",
    "        ]\n",
    "\n",
    "        self.features = nn.SequentialCell(self.layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        output = self.features(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "def mobilenetv1(num_classes: int):\n",
    "    backbone = MobileNetV1()\n",
    "    head = nn.Dense(1024, num_classes)\n",
    "    model = BaseClassifier(backbone, head)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 模型训练与推理\n",
    "\n",
    "本案例基于MindSpore-GPU版本，在单GPU卡上完成模型训练和验证。\n",
    "\n",
    "首先导入相关模块，配置相关超参数并读取数据集，该部分代码在Vision套件中都有API可直接调用，详情可以参考以下链接：https://gitee.com/mindspore/vision 。\n",
    "\n",
    "可通过:http://image-net.org/ 进行数据集下载。\n",
    "\n",
    "加载前先定义数据集路径，请确保你的数据集路径如以下结构。\n",
    "\n",
    "```text\n",
    ".ImageNet/\n",
    "    ├── ILSVRC2012_devkit_t12.tar.gz\n",
    "    ├── train/\n",
    "    ├── val/\n",
    "    └── mobilenet_infer.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 模型训练\n",
    "\n",
    "训练模型前，需要先按照论文中给出的参数设置损失函数，优化器以及回调函数，MindSpore Vision套件提供了提供了相应的接口，具体代码如下所示。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from mindspore import context\n",
    "from mindspore.common import set_seed\n",
    "from mindspore.communication import init, get_rank, get_group_size\n",
    "from mindspore.context import ParallelMode\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor\n",
    "\n",
    "from mindvision.classification.dataset import ImageNet\n",
    "from mindvision.engine.loss import CrossEntropySmooth\n",
    "\n",
    "set_seed(1)\n",
    "\n",
    "\n",
    "def mobilenet_v1_train(args_opt):\n",
    "    \"\"\"MobileNetV1 train.\"\"\"\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=args_opt.device_target)\n",
    "\n",
    "    # Data Pipeline.\n",
    "    if args_opt.run_distribute:\n",
    "        init(\"nccl\")\n",
    "        rank_id = get_rank()\n",
    "        device_num = get_group_size()\n",
    "        context.set_auto_parallel_context(device_num=device_num,\n",
    "                                          parallel_mode=ParallelMode.DATA_PARALLEL,\n",
    "                                          gradients_mean=True)\n",
    "        dataset = ImageNet(args_opt.data_url,\n",
    "                           split=\"train\",\n",
    "                           num_parallel_workers=args_opt.num_parallel_workers,\n",
    "                           shuffle=True,\n",
    "                           resize=args_opt.resize,\n",
    "                           num_shards=device_num,\n",
    "                           shard_id=rank_id,\n",
    "                           batch_size=args_opt.batch_size,\n",
    "                           repeat_num=args_opt.repeat_num)\n",
    "        ckpt_save_dir = args_opt.ckpt_save_dir + \"_ckpt_\" + str(rank_id) + \"/\"\n",
    "    else:\n",
    "        dataset = ImageNet(args_opt.data_url,\n",
    "                           split=\"train\",\n",
    "                           num_parallel_workers=args_opt.num_parallel_workers,\n",
    "                           shuffle=True,\n",
    "                           resize=args_opt.resize,\n",
    "                           batch_size=args_opt.batch_size,\n",
    "                           repeat_num=args_opt.repeat_num)\n",
    "        ckpt_save_dir = args_opt.ckpt_save_dir\n",
    "\n",
    "    dataset_train = dataset.run()\n",
    "    step_size = dataset_train.get_dataset_size()\n",
    "\n",
    "    # Create model.\n",
    "    network = mobilenetv1(args_opt.num_classes)\n",
    "\n",
    "    # Set lr scheduler.\n",
    "    if args_opt.lr_decay_mode == 'cosine_decay_lr':\n",
    "        lr = nn.cosine_decay_lr(min_lr=args_opt.min_lr, max_lr=args_opt.max_lr,\n",
    "                                total_step=args_opt.epoch_size * step_size, step_per_epoch=step_size,\n",
    "                                decay_epoch=args_opt.decay_epoch)\n",
    "    elif args_opt.lr_decay_mode == 'piecewise_constant_lr':\n",
    "        lr = nn.piecewise_constant_lr(args_opt.milestone, args_opt.learning_rates)\n",
    "\n",
    "    # Define optimizer.\n",
    "    network_opt = nn.Momentum(network.trainable_params(), lr, args_opt.momentum)\n",
    "\n",
    "    # Define loss function.\n",
    "    network_loss = CrossEntropySmooth(sparse=True, reduction=\"mean\", smooth_factor=args_opt.smooth_factor,\n",
    "                                      classes_num=args_opt.num_classes)\n",
    "\n",
    "    # Define metrics.\n",
    "    metrics = {'acc'}\n",
    "\n",
    "    # Set the checkpoint config for the network.\n",
    "    time_cb = TimeMonitor(data_size=step_size)\n",
    "    loss_cb = LossMonitor()\n",
    "    cb = [time_cb, loss_cb]\n",
    "    ckpt_config = CheckpointConfig(\n",
    "        save_checkpoint_steps=step_size,\n",
    "        keep_checkpoint_max=args_opt.keep_checkpoint_max)\n",
    "    ckpt_cb = ModelCheckpoint(prefix=\"mobilenetv1\", directory=ckpt_save_dir, config=ckpt_config)\n",
    "    cb += [ckpt_cb]\n",
    "\n",
    "    # Init the model.\n",
    "    model = Model(network, loss_fn=network_loss, optimizer=network_opt, metrics=metrics)\n",
    "\n",
    "    # Begin to train.\n",
    "    model.train(args_opt.epoch_size,\n",
    "                dataset_train,\n",
    "                callbacks=cb,\n",
    "                dataset_sink_mode=args_opt.dataset_sink_mode)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='MobileNetV1 train.')\n",
    "    parser.add_argument('--device_target', type=str, default=\"GPU\", choices=[\"Ascend\", \"GPU\", \"CPU\"])\n",
    "    parser.add_argument('--data_url', required=True, default=None, help='Location of data.')\n",
    "    parser.add_argument('--epoch_size', type=int, default=200, help='Train epoch size.')\n",
    "    parser.add_argument('--keep_checkpoint_max', type=int, default=10, help='Max number of checkpoint files.')\n",
    "    parser.add_argument('--ckpt_save_dir', type=str, default=\"./mobilenet_v1\", help='Location of training outputs.')\n",
    "    parser.add_argument('--num_parallel_workers', type=int, default=8, help='Number of parallel workers.')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, help='Number of batch size.')\n",
    "    parser.add_argument('--repeat_num', type=int, default=1, help='Number of repeat.')\n",
    "    parser.add_argument('--num_classes', type=int, default=1001, help='Number of classification.')\n",
    "    parser.add_argument('--lr_decay_mode', type=str, default=\"cosine_decay_lr\", help='Learning rate decay mode.')\n",
    "    parser.add_argument('--min_lr', type=float, default=0.0, help='The minimum learning rate.')\n",
    "    parser.add_argument('--max_lr', type=float, default=0.1, help='The maximum learning rate.')\n",
    "    parser.add_argument('--decay_epoch', type=int, default=200, help='Number of decay epochs.')\n",
    "    parser.add_argument('--milestone', type=list, default=None, help='A list of milestone.')\n",
    "    parser.add_argument('--learning_rates', type=list, default=None, help='A list of learning rates.')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, help='Momentum for the moving average.')\n",
    "    parser.add_argument('--smooth_factor', type=float, default=0.1, help='Label smoothing factor.')\n",
    "    parser.add_argument('--dataset_sink_mode', type=bool, default=True, help='The dataset sink mode.')\n",
    "    parser.add_argument('--run_distribute', type=bool, default=True, help='Distributed parallel training.')\n",
    "\n",
    "    args = parser.parse_known_args()[0]\n",
    "    mobilenet_v1_train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```text\n",
    "epoch: 89 step: 1251, loss is 2.44095\n",
    "Epoch time: 322114.519, per step time: 257.486\n",
    "epoch: 90 step: 1251, loss is 2.2521682\n",
    "Epoch time: 320744.265, per step time: 256.390\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 模型验证\n",
    "\n",
    "模型验证过程与训练过程相似。不同的是验证过程不需要设置优化器，但是需要设置评价指标\n",
    "\n",
    "调用ImageNet验证集数据的只需要将接口的split参数设置为\"val\"即可，具体代码如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "\n",
    "\n",
    "def mobilenet_v1_eval(args_opt):\n",
    "    \"\"\"MobileNetV1 eval.\"\"\"\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=args_opt.device_target)\n",
    "\n",
    "    # Data pipeline.\n",
    "    dataset_path = args_opt.data_url\n",
    "\n",
    "    dataset = ImageNet(dataset_path,\n",
    "                       split=\"val\",\n",
    "                       num_parallel_workers=args_opt.num_parallel_workers,\n",
    "                       resize=args_opt.resize,\n",
    "                       batch_size=args_opt.batch_size)\n",
    "\n",
    "    dataset_eval = dataset.run()\n",
    "\n",
    "    # Create model.\n",
    "    network = mobilenetv1(args_opt.num_classes)\n",
    "\n",
    "    # Define loss function.\n",
    "    network_loss = CrossEntropySmooth(sparse=True, reduction=\"mean\",\n",
    "                                      smooth_factor=args_opt.smooth_factor,\n",
    "                                      classes_num=args_opt.num_classes)\n",
    "\n",
    "    # Define eval metrics.\n",
    "    eval_metrics = {'Top_1_Accuracy': nn.Top1CategoricalAccuracy(),\n",
    "                    'Top_5_Accuracy': nn.Top5CategoricalAccuracy()}\n",
    "\n",
    "    # Init the model.\n",
    "    model = Model(network, network_loss, metrics=eval_metrics)\n",
    "    param_dict = ms.load_checkpoint(args_opt.checkpoint_path)\n",
    "    ms.load_param_into_net(model, param_dict)\n",
    "    model.set_train(False)\n",
    "\n",
    "    # Begin to eval\n",
    "    result = model.eval(dataset_eval)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='MobileNetV1 eval.')\n",
    "    parser.add_argument('--device_target', type=str, default=\"GPU\", choices=[\"Ascend\", \"GPU\", \"CPU\"])\n",
    "    parser.add_argument('--data_url', required=True, default=None, help='Location of data.')\n",
    "    parser.add_argument('--checkpoint_path', required=True, default=None, help='Path of checkpoint file.')\n",
    "    parser.add_argument('--num_parallel_workers', type=int, default=8, help='Number of parallel workers.')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, help='Number of batch size.')\n",
    "    parser.add_argument('--num_classes', type=int, default=1001, help='Number of classification.')\n",
    "    parser.add_argument('--smooth_factor', type=float, default=0.1, help='The smooth factor.')\n",
    "\n",
    "    args = parser.parse_known_args()[0]\n",
    "    mobilenet_v1_eval(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "{'Top_1_Accuracy': 0.71292, 'Top_5_Accuracy': 0.90112}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 总结\n",
    "\n",
    "本案例对MobileNet的论文中提出的深度可分离卷积结构和模型缩放算法进行了详细的解释，向读者完整地呈现了该算法的核心问题的解析。\n",
    "\n",
    "同时，通过MindSpore Vision套件，剖析了MobileNetV1的主要模块和主体结构，还展示了MobileNetV1 模型在ImageNet数据上的训练，验证和推理的过程。\n",
    "\n",
    "## 引用\n",
    "\n",
    "[1] Howard A G, Zhu M, Chen B, et al. Mobilenets: Efficient convolutional neural networks for mobile vision applications[J]. arXiv preprint arXiv:1704.04861, 2017.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
